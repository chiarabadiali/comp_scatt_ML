{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import progressbar\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Dependencies\n",
    "\n",
    "\n",
    "\n",
    "Dependences are fundamental to record the computational environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "pandas    : 1.2.3\n",
      "keras     : 2.4.3\n",
      "numpy     : 1.19.5\n",
      "math      : unknown\n",
      "tensorflow: 2.4.1\n",
      "matplotlib: 3.4.0\n",
      "h5py      : 2.10.0\n",
      "\n",
      "Compiler    : Clang 12.0.0 (clang-1200.0.32.29)\n",
      "OS          : Darwin\n",
      "Release     : 19.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      " \n",
      "Last updated: Thu Apr 01 2021 16:43:53CEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p pandas,keras,numpy,math,tensorflow,matplotlib,h5py\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of the data\n",
    "\n",
    "   You can also load all of them! Writing \"all_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import loaddata\n",
    "class_data = loaddata(\"../data_old/{}.csv\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = class_data[class_data[:,0] > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.62262057e-01  2.84130793e-01  4.09051607e-01  1.68263575e-02\n",
      "  3.03554544e-01 -7.44853335e-02 -3.22025145e-01  2.42000000e+00\n",
      "  3.61999998e+09  1.47123523e-01  3.15814976e-01 -2.38351380e-01\n",
      " -4.87117266e-01  5.11761358e-03]\n",
      "[ 2.62262057e-01  2.84130793e-01  4.09051607e-01  1.68263575e-02\n",
      "  3.03554544e-01 -7.44853335e-02 -3.22025145e-01  2.42000000e+00\n",
      "  3.61999998e+09  5.11761358e-03  3.15814976e-01 -2.38351380e-01\n",
      " -4.87117266e-01  5.11761358e-03]\n",
      "[ 2.84130793e-01  4.09051607e-01  1.68263575e-02  3.03554544e-01\n",
      " -7.44853335e-02 -3.22025145e-01  2.42000000e+00  3.61999998e+09\n",
      "  5.11761358e-03]\n",
      "(135911, 9)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(class_data)\n",
    "y = class_data[:,0]\n",
    "A = class_data\n",
    "print(A[0])\n",
    "A[:,9] = A[:,13]\n",
    "print(A[0])\n",
    "x = class_data[:,1:10]\n",
    "print(x[0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 13, 10, 11, 12, 13]\n",
      "[11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "prova = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "a = prova\n",
    "a[9] = a[13]\n",
    "print(a)\n",
    "#I want to remove [9,10,11,12] that are the positions\n",
    "b = prova[11:14]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample: 101933 \n",
      "Valuation sample: 33978\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.75\n",
    "train_limit = int(len(y)*train_split)\n",
    "print(\"Training sample: {0} \\nValuation sample: {1}\".format(train_limit, len(y)-train_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:train_limit]\n",
    "x_val = x[train_limit:]\n",
    "\n",
    "y_train = y[:train_limit]\n",
    "y_val = y[train_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def root_mean_squared_log_error(y, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(1+y_pred) - K.log(1+y))))\n",
    "\n",
    "def maape(y, y_pred):\n",
    "    return K.mean(K.mean(K.atan(K.abs((y-ypred)/y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add (BatchNormalization(input_dim = 9))\n",
    "    model.add (layers.Dense (18 , activation = \"sigmoid\"))\n",
    "    model.add (layers.Dense (36, activation = \"relu\"))\n",
    "    model.add (layers.Dense (72 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (144 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (72, activation = \"relu\"))\n",
    "    model.add (layers.Dense (36 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (18, activation = \"relu\"))\n",
    "    model.add (layers.Dense (9 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (1 , activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\" , loss = 'mae' , metrics = [\"mape\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7856 - mape: 852.6989 - val_loss: 0.7766 - val_mape: 823.0944\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7766 - mape: 842.8867 - val_loss: 0.7677 - val_mape: 813.4816\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7677 - mape: 833.0677 - val_loss: 0.7590 - val_mape: 803.8676\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7590 - mape: 823.2478 - val_loss: 0.7505 - val_mape: 794.2583\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7505 - mape: 813.4327 - val_loss: 0.7421 - val_mape: 784.6588\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7421 - mape: 803.6275 - val_loss: 0.7339 - val_mape: 775.0746\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7339 - mape: 793.8377 - val_loss: 0.7255 - val_mape: 765.0324\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7255 - mape: 783.5801 - val_loss: 0.7167 - val_mape: 754.3456\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7167 - mape: 772.6641 - val_loss: 0.7079 - val_mape: 743.4471\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7079 - mape: 761.5318 - val_loss: 0.6992 - val_mape: 732.4152\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6992 - mape: 750.2635 - val_loss: 0.6906 - val_mape: 721.2966\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6906 - mape: 738.9064 - val_loss: 0.6821 - val_mape: 710.1234\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6821 - mape: 727.4938 - val_loss: 0.6738 - val_mape: 698.9203\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6738 - mape: 716.0507 - val_loss: 0.6657 - val_mape: 687.7063\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6657 - mape: 704.5960 - val_loss: 0.6582 - val_mape: 677.1220\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6581 - mape: 693.7844 - val_loss: 0.6511 - val_mape: 667.0624\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6511 - mape: 683.5086 - val_loss: 0.6443 - val_mape: 657.0385\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6443 - mape: 673.2690 - val_loss: 0.6376 - val_mape: 647.0542\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6376 - mape: 663.0700 - val_loss: 0.6311 - val_mape: 637.1138\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6311 - mape: 652.9158 - val_loss: 0.6247 - val_mape: 627.2220\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6247 - mape: 642.8106 - val_loss: 0.6185 - val_mape: 617.3821\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6185 - mape: 632.7584 - val_loss: 0.6125 - val_mape: 607.5975\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6125 - mape: 622.7631 - val_loss: 0.6066 - val_mape: 597.8726\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6066 - mape: 612.8282 - val_loss: 0.6009 - val_mape: 588.2103\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6009 - mape: 602.9581 - val_loss: 0.5953 - val_mape: 578.6136\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5953 - mape: 593.1559 - val_loss: 0.5899 - val_mape: 569.0868\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5899 - mape: 583.4245 - val_loss: 0.5846 - val_mape: 559.6332\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5846 - mape: 573.7675 - val_loss: 0.5795 - val_mape: 550.2557\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5795 - mape: 564.1881 - val_loss: 0.5746 - val_mape: 540.9577\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5745 - mape: 554.6902 - val_loss: 0.5698 - val_mape: 531.7425\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5697 - mape: 545.2769 - val_loss: 0.5651 - val_mape: 522.6140\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5651 - mape: 535.9518 - val_loss: 0.5606 - val_mape: 513.5757\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5606 - mape: 526.7185 - val_loss: 0.5562 - val_mape: 504.6297\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5562 - mape: 517.5807 - val_loss: 0.5520 - val_mape: 495.7799\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5520 - mape: 508.5422 - val_loss: 0.5479 - val_mape: 487.0290\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5479 - mape: 499.6060 - val_loss: 0.5440 - val_mape: 478.3828\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5439 - mape: 490.7762 - val_loss: 0.5402 - val_mape: 469.8448\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5401 - mape: 482.0565 - val_loss: 0.5365 - val_mape: 461.4194\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5365 - mape: 473.4507 - val_loss: 0.5330 - val_mape: 453.1107\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5329 - mape: 464.9632 - val_loss: 0.5296 - val_mape: 444.9210\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5295 - mape: 456.5980 - val_loss: 0.5263 - val_mape: 436.8563\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5263 - mape: 448.3606 - val_loss: 0.5233 - val_mape: 429.3669\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5233 - mape: 440.7113 - val_loss: 0.5205 - val_mape: 422.0574\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5205 - mape: 433.2458 - val_loss: 0.5178 - val_mape: 414.8593\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5178 - mape: 425.8951 - val_loss: 0.5152 - val_mape: 407.7788\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5152 - mape: 418.6650 - val_loss: 0.5127 - val_mape: 400.8201\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5127 - mape: 411.5592 - val_loss: 0.5103 - val_mape: 393.9892\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5103 - mape: 404.5829 - val_loss: 0.5080 - val_mape: 387.2916\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5080 - mape: 397.7407 - val_loss: 0.5058 - val_mape: 380.7310\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5058 - mape: 391.0370 - val_loss: 0.5038 - val_mape: 374.3105\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5037 - mape: 384.4767 - val_loss: 0.5018 - val_mape: 368.0352\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5017 - mape: 378.0641 - val_loss: 0.4999 - val_mape: 361.9110\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4999 - mape: 371.8027 - val_loss: 0.4981 - val_mape: 355.9695\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4981 - mape: 365.7261 - val_loss: 0.4964 - val_mape: 350.1287\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - mape: 359.7518 - val_loss: 0.4948 - val_mape: 344.4749\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4947 - mape: 353.9684 - val_loss: 0.4933 - val_mape: 338.9816\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4932 - mape: 348.3466 - val_loss: 0.4918 - val_mape: 333.6505\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4918 - mape: 342.8876 - val_loss: 0.4905 - val_mape: 328.4825\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4904 - mape: 337.5942 - val_loss: 0.4892 - val_mape: 323.4767\n",
      "Epoch 60/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4891 - mape: 332.4650 - val_loss: 0.4880 - val_mape: 318.6304\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4879 - mape: 327.4985 - val_loss: 0.4869 - val_mape: 313.9461\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4868 - mape: 322.6956 - val_loss: 0.4858 - val_mape: 309.4206\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4858 - mape: 318.0567 - val_loss: 0.4848 - val_mape: 305.0522\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4848 - mape: 313.5793 - val_loss: 0.4839 - val_mape: 300.8366\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4839 - mape: 309.2603 - val_loss: 0.4831 - val_mape: 296.7731\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4830 - mape: 305.0988 - val_loss: 0.4823 - val_mape: 292.8623\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4822 - mape: 301.0924 - val_loss: 0.4816 - val_mape: 289.1010\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - mape: 297.2393 - val_loss: 0.4809 - val_mape: 285.4872\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4808 - mape: 293.5354 - val_loss: 0.4803 - val_mape: 282.0174\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4802 - mape: 289.9774 - val_loss: 0.4797 - val_mape: 278.6888\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4796 - mape: 286.5627 - val_loss: 0.4792 - val_mape: 275.4981\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4791 - mape: 283.2888 - val_loss: 0.4787 - val_mape: 272.4420\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4786 - mape: 280.1512 - val_loss: 0.4782 - val_mape: 269.5167\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - mape: 277.1478 - val_loss: 0.4778 - val_mape: 266.7205\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4778 - mape: 274.2762 - val_loss: 0.4775 - val_mape: 264.0491\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4774 - mape: 271.5331 - val_loss: 0.4772 - val_mape: 261.4990\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4771 - mape: 268.9145 - val_loss: 0.4769 - val_mape: 259.0686\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4768 - mape: 266.4173 - val_loss: 0.4766 - val_mape: 256.7541\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4766 - mape: 264.0385 - val_loss: 0.4764 - val_mape: 254.5510\n",
      "Epoch 80/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4763 - mape: 261.7741 - val_loss: 0.4762 - val_mape: 252.4564\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4761 - mape: 259.6215 - val_loss: 0.4760 - val_mape: 250.4667\n",
      "Epoch 82/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4759 - mape: 257.5772 - val_loss: 0.4758 - val_mape: 248.5782\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4758 - mape: 255.6376 - val_loss: 0.4757 - val_mape: 246.7885\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4756 - mape: 253.7991 - val_loss: 0.4755 - val_mape: 245.0937\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4755 - mape: 252.0590 - val_loss: 0.4754 - val_mape: 243.4909\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4754 - mape: 250.4141 - val_loss: 0.4753 - val_mape: 241.9775\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4753 - mape: 248.8613 - val_loss: 0.4752 - val_mape: 240.5509\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4752 - mape: 247.3971 - val_loss: 0.4752 - val_mape: 239.2078\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4751 - mape: 246.0184 - val_loss: 0.4751 - val_mape: 237.9444\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4751 - mape: 244.7219 - val_loss: 0.4751 - val_mape: 236.7585\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4750 - mape: 243.5050 - val_loss: 0.4750 - val_mape: 235.6469\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4750 - mape: 242.3645 - val_loss: 0.4750 - val_mape: 234.6070\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4749 - mape: 241.2977 - val_loss: 0.4749 - val_mape: 233.6359\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4749 - mape: 240.3017 - val_loss: 0.4749 - val_mape: 232.7310\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4749 - mape: 239.3731 - val_loss: 0.4749 - val_mape: 231.8894\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4749 - mape: 238.5094 - val_loss: 0.4749 - val_mape: 231.1082\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4748 - mape: 237.7079 - val_loss: 0.4749 - val_mape: 230.3848\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 236.9657 - val_loss: 0.4749 - val_mape: 229.7167\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 236.2801 - val_loss: 0.4749 - val_mape: 229.1015\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 235.6487 - val_loss: 0.4749 - val_mape: 228.5368\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 235.0690 - val_loss: 0.4748 - val_mape: 228.0199\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4748 - mape: 234.5384 - val_loss: 0.4748 - val_mape: 227.5485\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4748 - mape: 234.0544 - val_loss: 0.4748 - val_mape: 227.1203\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4748 - mape: 233.6147 - val_loss: 0.4748 - val_mape: 226.7331\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.2170 - val_loss: 0.4748 - val_mape: 226.3845\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 232.8591 - val_loss: 0.4748 - val_mape: 226.0725\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4748 - mape: 232.5387 - val_loss: 0.4749 - val_mape: 225.7949\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 232.2537 - val_loss: 0.4749 - val_mape: 225.5499\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4748 - mape: 232.0021 - val_loss: 0.4749 - val_mape: 225.3354\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 231.7819 - val_loss: 0.4749 - val_mape: 225.1494\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 231.5908 - val_loss: 0.4749 - val_mape: 224.9902\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 231.4273 - val_loss: 0.4749 - val_mape: 224.8560\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4748 - mape: 231.2895 - val_loss: 0.4749 - val_mape: 224.7453\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4748 - mape: 231.1757 - val_loss: 0.4749 - val_mape: 224.6559\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4748 - mape: 231.0840 - val_loss: 0.4749 - val_mape: 224.5867\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4748 - mape: 231.0128 - val_loss: 0.4749 - val_mape: 224.5360\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 230.9608 - val_loss: 0.4749 - val_mape: 224.5022\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 230.9261 - val_loss: 0.4749 - val_mape: 224.4841\n",
      "Epoch 119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 230.9075 - val_loss: 0.4749 - val_mape: 224.4802\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 230.9035 - val_loss: 0.4749 - val_mape: 224.4894\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 230.9129 - val_loss: 0.4749 - val_mape: 224.5102\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4748 - mape: 230.9343 - val_loss: 0.4749 - val_mape: 224.5416\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4748 - mape: 230.9665 - val_loss: 0.4749 - val_mape: 224.5824\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 231.0084 - val_loss: 0.4749 - val_mape: 224.6316\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 231.0590 - val_loss: 0.4749 - val_mape: 224.6882\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4748 - mape: 231.1171 - val_loss: 0.4749 - val_mape: 224.7512\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 231.1818 - val_loss: 0.4749 - val_mape: 224.8197\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 231.2522 - val_loss: 0.4749 - val_mape: 224.8929\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 231.3274 - val_loss: 0.4749 - val_mape: 224.9700\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4748 - mape: 231.4066 - val_loss: 0.4749 - val_mape: 225.0503\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4748 - mape: 231.4890 - val_loss: 0.4749 - val_mape: 225.1330\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4748 - mape: 231.5740 - val_loss: 0.4749 - val_mape: 225.2176\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4748 - mape: 231.6609 - val_loss: 0.4749 - val_mape: 225.3034\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4748 - mape: 231.7490 - val_loss: 0.4749 - val_mape: 225.3899\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4748 - mape: 231.8379 - val_loss: 0.4749 - val_mape: 225.4767\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4748 - mape: 231.9269 - val_loss: 0.4749 - val_mape: 225.5632\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4748 - mape: 232.0158 - val_loss: 0.4749 - val_mape: 225.6491\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 232.1040 - val_loss: 0.4749 - val_mape: 225.7338\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 232.1910 - val_loss: 0.4749 - val_mape: 225.8172\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 232.2766 - val_loss: 0.4748 - val_mape: 225.8990\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4748 - mape: 232.3606 - val_loss: 0.4748 - val_mape: 225.9787\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 232.4425 - val_loss: 0.4748 - val_mape: 226.0564\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 232.5222 - val_loss: 0.4748 - val_mape: 226.1316\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 232.5995 - val_loss: 0.4748 - val_mape: 226.2043\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 232.6741 - val_loss: 0.4748 - val_mape: 226.2742\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4748 - mape: 232.7459 - val_loss: 0.4748 - val_mape: 226.3414\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 232.8148 - val_loss: 0.4748 - val_mape: 226.4056\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4748 - mape: 232.8808 - val_loss: 0.4748 - val_mape: 226.4668\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 232.9436 - val_loss: 0.4748 - val_mape: 226.5251\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 233.0034 - val_loss: 0.4748 - val_mape: 226.5802\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4748 - mape: 233.0600 - val_loss: 0.4748 - val_mape: 226.6322\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4748 - mape: 233.1135 - val_loss: 0.4748 - val_mape: 226.6812\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.1637 - val_loss: 0.4748 - val_mape: 226.7271\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4748 - mape: 233.2109 - val_loss: 0.4748 - val_mape: 226.7701\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 233.2550 - val_loss: 0.4748 - val_mape: 226.8100\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.2961 - val_loss: 0.4748 - val_mape: 226.8470\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4748 - mape: 233.3340 - val_loss: 0.4748 - val_mape: 226.8812\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4748 - mape: 233.3691 - val_loss: 0.4748 - val_mape: 226.9125\n",
      "Epoch 159/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4013 - val_loss: 0.4748 - val_mape: 226.9412\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4748 - mape: 233.4307 - val_loss: 0.4748 - val_mape: 226.9674\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4577 - val_loss: 0.4748 - val_mape: 226.9910\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4819 - val_loss: 0.4748 - val_mape: 227.0122\n",
      "Epoch 163/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4748 - mape: 233.5037 - val_loss: 0.4748 - val_mape: 227.0311\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4748 - mape: 233.5230 - val_loss: 0.4748 - val_mape: 227.0478\n",
      "Epoch 165/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4748 - mape: 233.5402 - val_loss: 0.4748 - val_mape: 227.0625\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4748 - mape: 233.5553 - val_loss: 0.4748 - val_mape: 227.0751\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4748 - mape: 233.5683 - val_loss: 0.4748 - val_mape: 227.0860\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4748 - mape: 233.5794 - val_loss: 0.4748 - val_mape: 227.0951\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4748 - mape: 233.5888 - val_loss: 0.4748 - val_mape: 227.1025\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.5964 - val_loss: 0.4748 - val_mape: 227.1085\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4748 - mape: 233.6025 - val_loss: 0.4748 - val_mape: 227.1130\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 233.6071 - val_loss: 0.4748 - val_mape: 227.1162\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4748 - mape: 233.6104 - val_loss: 0.4748 - val_mape: 227.1183\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 233.6126 - val_loss: 0.4748 - val_mape: 227.1191\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.6135 - val_loss: 0.4748 - val_mape: 227.1191\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4748 - mape: 233.6134 - val_loss: 0.4748 - val_mape: 227.1181\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.6124 - val_loss: 0.4748 - val_mape: 227.1163\n",
      "Epoch 178/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4748 - mape: 233.6106 - val_loss: 0.4748 - val_mape: 227.1138\n",
      "Epoch 179/5000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4748 - mape: 233.6080 - val_loss: 0.4748 - val_mape: 227.1106\n",
      "Epoch 180/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.6047 - val_loss: 0.4748 - val_mape: 227.1068\n",
      "Epoch 181/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.6008 - val_loss: 0.4748 - val_mape: 227.1026\n",
      "Epoch 182/5000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4748 - mape: 233.5965 - val_loss: 0.4748 - val_mape: 227.0980\n",
      "Epoch 183/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4748 - mape: 233.5917 - val_loss: 0.4748 - val_mape: 227.0930\n",
      "Epoch 184/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 233.5867 - val_loss: 0.4748 - val_mape: 227.0877\n",
      "Epoch 185/5000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4748 - mape: 233.5812 - val_loss: 0.4748 - val_mape: 227.0822\n",
      "Epoch 186/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.5756 - val_loss: 0.4748 - val_mape: 227.0765\n",
      "Epoch 187/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4748 - mape: 233.5697 - val_loss: 0.4748 - val_mape: 227.0708\n",
      "Epoch 188/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.5638 - val_loss: 0.4748 - val_mape: 227.0649\n",
      "Epoch 189/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4748 - mape: 233.5578 - val_loss: 0.4748 - val_mape: 227.0590\n",
      "Epoch 190/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.5517 - val_loss: 0.4748 - val_mape: 227.0531\n",
      "Epoch 191/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 233.5456 - val_loss: 0.4748 - val_mape: 227.0472\n",
      "Epoch 192/5000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4748 - mape: 233.5396 - val_loss: 0.4748 - val_mape: 227.0415\n",
      "Epoch 193/5000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4748 - mape: 233.5338 - val_loss: 0.4748 - val_mape: 227.0358\n",
      "Epoch 194/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4748 - mape: 233.5279 - val_loss: 0.4748 - val_mape: 227.0303\n",
      "Epoch 195/5000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4748 - mape: 233.5223 - val_loss: 0.4748 - val_mape: 227.0250\n",
      "Epoch 196/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4748 - mape: 233.5168 - val_loss: 0.4748 - val_mape: 227.0198\n",
      "Epoch 197/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4748 - mape: 233.5114 - val_loss: 0.4748 - val_mape: 227.0149\n",
      "Epoch 198/5000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4748 - mape: 233.5064 - val_loss: 0.4748 - val_mape: 227.0100\n",
      "Epoch 199/5000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4748 - mape: 233.50 - 0s 83ms/step - loss: 0.4748 - mape: 233.5014 - val_loss: 0.4748 - val_mape: 227.0054\n",
      "Epoch 200/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4966 - val_loss: 0.4748 - val_mape: 227.0011\n",
      "Epoch 201/5000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4748 - mape: 233.4922 - val_loss: 0.4748 - val_mape: 226.9970\n",
      "Epoch 202/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.4880 - val_loss: 0.4748 - val_mape: 226.9930\n",
      "Epoch 203/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 233.4840 - val_loss: 0.4748 - val_mape: 226.9894\n",
      "Epoch 204/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4802 - val_loss: 0.4748 - val_mape: 226.9860\n",
      "Epoch 205/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4767 - val_loss: 0.4748 - val_mape: 226.9828\n",
      "Epoch 206/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4735 - val_loss: 0.4748 - val_mape: 226.9799\n",
      "Epoch 207/5000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4748 - mape: 233.4705 - val_loss: 0.4748 - val_mape: 226.9772\n",
      "Epoch 208/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4677 - val_loss: 0.4748 - val_mape: 226.9747\n",
      "Epoch 209/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4652 - val_loss: 0.4748 - val_mape: 226.9725\n",
      "Epoch 210/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4628 - val_loss: 0.4748 - val_mape: 226.9704\n",
      "Epoch 211/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4748 - mape: 233.4608 - val_loss: 0.4748 - val_mape: 226.9686\n",
      "Epoch 212/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4748 - mape: 233.4589 - val_loss: 0.4748 - val_mape: 226.9670\n",
      "Epoch 213/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4572 - val_loss: 0.4748 - val_mape: 226.9656\n",
      "Epoch 214/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4748 - mape: 233.4558 - val_loss: 0.4748 - val_mape: 226.9644\n",
      "Epoch 215/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.4545 - val_loss: 0.4748 - val_mape: 226.9633\n",
      "Epoch 216/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 233.4534 - val_loss: 0.4748 - val_mape: 226.9623\n",
      "Epoch 217/5000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4748 - mape: 233.4524 - val_loss: 0.4748 - val_mape: 226.9617\n",
      "Epoch 218/5000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4748 - mape: 233.4517 - val_loss: 0.4748 - val_mape: 226.9610\n",
      "Epoch 219/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4511 - val_loss: 0.4748 - val_mape: 226.9605\n",
      "Epoch 220/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4506 - val_loss: 0.4748 - val_mape: 226.9602\n",
      "Epoch 221/5000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4748 - mape: 233.4503 - val_loss: 0.4748 - val_mape: 226.9601\n",
      "Epoch 222/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4501 - val_loss: 0.4748 - val_mape: 226.9599\n",
      "Epoch 223/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4748 - mape: 233.4500 - val_loss: 0.4748 - val_mape: 226.9599\n",
      "Epoch 224/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4748 - mape: 233.4500 - val_loss: 0.4748 - val_mape: 226.9600\n",
      "Epoch 225/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.4501 - val_loss: 0.4748 - val_mape: 226.9601\n",
      "Epoch 226/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4502 - val_loss: 0.4748 - val_mape: 226.9604\n",
      "Epoch 227/5000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4748 - mape: 233.4504 - val_loss: 0.4748 - val_mape: 226.9606\n",
      "Epoch 228/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 233.4507 - val_loss: 0.4748 - val_mape: 226.9610\n",
      "Epoch 229/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4511 - val_loss: 0.4748 - val_mape: 226.9614\n",
      "Epoch 230/5000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4748 - mape: 233.4515 - val_loss: 0.4748 - val_mape: 226.9618\n",
      "Epoch 231/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 233.4519 - val_loss: 0.4748 - val_mape: 226.9623\n",
      "Epoch 232/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4748 - mape: 233.4524 - val_loss: 0.4748 - val_mape: 226.9627\n",
      "Epoch 233/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.4528 - val_loss: 0.4748 - val_mape: 226.9633\n",
      "Epoch 234/5000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4748 - mape: 233.4534 - val_loss: 0.4748 - val_mape: 226.9638\n",
      "Epoch 235/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4539 - val_loss: 0.4748 - val_mape: 226.9643\n",
      "Epoch 236/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4544 - val_loss: 0.4748 - val_mape: 226.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4748 - mape: 233.4551 - val_loss: 0.4748 - val_mape: 226.9654\n",
      "Epoch 238/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4748 - mape: 233.4556 - val_loss: 0.4748 - val_mape: 226.9659\n",
      "Epoch 239/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4561 - val_loss: 0.4748 - val_mape: 226.9664\n",
      "Epoch 240/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4748 - mape: 233.4566 - val_loss: 0.4748 - val_mape: 226.9670\n",
      "Epoch 241/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4572 - val_loss: 0.4748 - val_mape: 226.9674\n",
      "Epoch 242/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4576 - val_loss: 0.4748 - val_mape: 226.9680\n",
      "Epoch 243/5000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4748 - mape: 233.4583 - val_loss: 0.4748 - val_mape: 226.9684\n",
      "Epoch 244/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4748 - mape: 233.4587 - val_loss: 0.4748 - val_mape: 226.9689\n",
      "Epoch 245/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4748 - mape: 233.4592 - val_loss: 0.4748 - val_mape: 226.9694\n",
      "Epoch 246/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4748 - mape: 233.4597 - val_loss: 0.4748 - val_mape: 226.9697\n",
      "Epoch 247/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4600 - val_loss: 0.4748 - val_mape: 226.9701\n",
      "Epoch 248/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4604 - val_loss: 0.4748 - val_mape: 226.9706\n",
      "Epoch 249/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4748 - mape: 233.4609 - val_loss: 0.4748 - val_mape: 226.9709\n",
      "Epoch 250/5000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4748 - mape: 233.4612 - val_loss: 0.4748 - val_mape: 226.9711\n",
      "Epoch 251/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4748 - mape: 233.4615 - val_loss: 0.4748 - val_mape: 226.9714\n",
      "Epoch 252/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.4618 - val_loss: 0.4748 - val_mape: 226.9718\n",
      "Epoch 253/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4622 - val_loss: 0.4748 - val_mape: 226.9720\n",
      "Epoch 254/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4623 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 255/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9724\n",
      "Epoch 256/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4748 - mape: 233.4628 - val_loss: 0.4748 - val_mape: 226.9726\n",
      "Epoch 257/5000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - mape: 233.4630 - val_loss: 0.4748 - val_mape: 226.9727\n",
      "Epoch 258/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4631 - val_loss: 0.4748 - val_mape: 226.9729\n",
      "Epoch 259/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4748 - mape: 233.4633 - val_loss: 0.4748 - val_mape: 226.9730\n",
      "Epoch 260/5000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9731\n",
      "Epoch 261/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 262/5000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4748 - mape: 233.4636 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 263/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.4636 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 264/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 265/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 266/5000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 267/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 268/5000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 269/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 270/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 271/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 233.4636 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 272/5000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 273/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9733\n",
      "Epoch 274/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 275/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4748 - mape: 233.4637 - val_loss: 0.4748 - val_mape: 226.9732\n",
      "Epoch 276/5000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - mape: 233.4636 - val_loss: 0.4748 - val_mape: 226.9731\n",
      "Epoch 277/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9730\n",
      "Epoch 278/5000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9730\n",
      "Epoch 279/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9730\n",
      "Epoch 280/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4635 - val_loss: 0.4748 - val_mape: 226.9729\n",
      "Epoch 281/5000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4748 - mape: 233.4633 - val_loss: 0.4748 - val_mape: 226.9729\n",
      "Epoch 282/5000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4748 - mape: 233.4633 - val_loss: 0.4748 - val_mape: 226.9728\n",
      "Epoch 283/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4632 - val_loss: 0.4748 - val_mape: 226.9728\n",
      "Epoch 284/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4748 - mape: 233.4632 - val_loss: 0.4748 - val_mape: 226.9727\n",
      "Epoch 285/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4631 - val_loss: 0.4748 - val_mape: 226.9727\n",
      "Epoch 286/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4631 - val_loss: 0.4748 - val_mape: 226.9726\n",
      "Epoch 287/5000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4748 - mape: 233.4630 - val_loss: 0.4748 - val_mape: 226.9726\n",
      "Epoch 288/5000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4748 - mape: 233.4630 - val_loss: 0.4748 - val_mape: 226.9725\n",
      "Epoch 289/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4629 - val_loss: 0.4748 - val_mape: 226.9725\n",
      "Epoch 290/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4748 - mape: 233.4629 - val_loss: 0.4748 - val_mape: 226.9724\n",
      "Epoch 291/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4748 - mape: 233.4628 - val_loss: 0.4748 - val_mape: 226.9724\n",
      "Epoch 292/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9724\n",
      "Epoch 293/5000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9724\n",
      "Epoch 294/5000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9723\n",
      "Epoch 295/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/5000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9723\n",
      "Epoch 297/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9723\n",
      "Epoch 298/5000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4748 - mape: 233.4627 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 299/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 300/5000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 301/5000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 302/5000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 303/5000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 304/5000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 305/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 306/5000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 307/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 308/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 309/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 310/5000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 311/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 312/5000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 313/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 314/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 315/5000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 316/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 317/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 318/5000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 319/5000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 320/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 321/5000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 322/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 323/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 324/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 325/5000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 326/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 327/5000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 328/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 329/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 330/5000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 331/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 332/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4748 - mape: 233.4626 - val_loss: 0.4748 - val_mape: 226.9722\n",
      "Epoch 333/5000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4748 - mape: 233.4626"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b2412ae6db75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/classifier/{}_noposition.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m       \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/ops/handle_data_util.py\u001b[0m in \u001b[0;36mcopy_handle_data\u001b[0;34m(source_t, target_t)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtarget_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mHandleData\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m   if (target_t.dtype == dtypes.resource or\n\u001b[0m\u001b[1;32m     54\u001b[0m       target_t.dtype == dtypes.variant):\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = build_model ()\n",
    "history = model.fit ( x_train, y_train, epochs = 5000, batch_size = 1000000 , validation_data = (x_val, y_val) )\n",
    "model.save(\"../models/classifier/{}_noposition.h5\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "accuracy = history.history['mape']\n",
    "val_accuracy = history.history['val_mape']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "l1 = ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "vl1 = ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss (mae))')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ac2= ax2.plot(epochs, accuracy, 'o', c=\"red\", label='Training acc')\n",
    "vac2= ax2.plot(epochs, val_accuracy, 'r', label='Validation acc')\n",
    "ax2.set_ylabel('mape')\n",
    "\n",
    "lns = l1 + vl1 + ac2 + vac2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=\"center right\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"acc+loss_drop.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(prob_array, bins):\n",
    "    prob_array = np.array(prob_array)\n",
    "    plt.hist(prob_array, bins, histtype=u'step', density=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "y = np.array(y)\n",
    "bins = np.linspace(0, 0.6, 100)\n",
    "pyplot.hist(y, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "pyplot.hist(y_pred, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.title('Trained on ($p_e$, $p_{\\gamma}$, $\\omega_e$, $\\omega_{\\gamma}$, n)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
