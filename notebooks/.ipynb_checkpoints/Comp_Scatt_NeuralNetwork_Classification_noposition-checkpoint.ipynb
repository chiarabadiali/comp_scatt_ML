{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import progressbar\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Dependencies\n",
    "\n",
    "\n",
    "\n",
    "Dependences are fundamental to record the computational environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "pandas    : 1.2.3\n",
      "keras     : 2.4.3\n",
      "numpy     : 1.19.5\n",
      "math      : unknown\n",
      "tensorflow: 2.4.1\n",
      "matplotlib: 3.4.0\n",
      "h5py      : 2.10.0\n",
      "\n",
      "Compiler    : Clang 12.0.0 (clang-1200.0.32.29)\n",
      "OS          : Darwin\n",
      "Release     : 19.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      " \n",
      "Last updated: Wed Apr 14 2021 11:29:48CEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p pandas,keras,numpy,math,tensorflow,matplotlib,h5py\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import loaddata\n",
    "class_data0 = loaddata(\"../data/{}.csv\".format('low_ene'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data0 = class_data0[class_data0[:,0] > 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "for class_ in class_data0:\n",
    "    if class_[0] > 0.12 and class_[0] < 0.25:\n",
    "        for i in range(8000):\n",
    "            data.append(class_) \n",
    "    if class_[0] > 0.065 and class_[0] < 0.1:\n",
    "        for i in range(6000):\n",
    "            data.append(class_) \n",
    "    if class_[0] > 0.25 and class_[0] < 0.35:\n",
    "        for i in range(6000):\n",
    "            data.append(class_) \n",
    "    if class_[0] > 0.4:\n",
    "        for i in range(10000):\n",
    "            data.append(class_) \n",
    "    else: \n",
    "        data.append(class_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)\n",
    "class_data = []\n",
    "class_data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961529, 14)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531585, 14)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22770357e-01  2.38940846e-01 -1.90164224e-01 -1.17584399e-01\n",
      " -1.33386558e-01 -7.88039621e-02  2.03525669e-01  4.43200000e+07\n",
      "  4.46400000e+07  2.00000000e-01  2.00000000e-01  0.00000000e+00\n",
      "  4.00000000e-01  9.71498363e-06]\n",
      "[ 1.22770357e-01  2.38940846e-01 -1.90164224e-01 -1.17584399e-01\n",
      " -1.33386558e-01 -7.88039621e-02  2.03525669e-01  4.43200000e+07\n",
      "  4.46400000e+07  9.71498363e-06  2.00000000e-01  0.00000000e+00\n",
      "  4.00000000e-01  9.71498363e-06]\n",
      "[ 2.38940846e-01 -1.90164224e-01 -1.17584399e-01 -1.33386558e-01\n",
      " -7.88039621e-02  2.03525669e-01  4.43200000e+07  4.46400000e+07\n",
      "  9.71498363e-06]\n",
      "(3961529, 9)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(class_data)\n",
    "y = class_data[:,0]\n",
    "A = class_data\n",
    "print(A[0])\n",
    "A[:,9] = A[:,13]\n",
    "print(A[0])\n",
    "x = class_data[:,1:10]\n",
    "print(x[0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if the data are balanced now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "y = np.array(y)\n",
    "bins = np.linspace(0, 0.55, 20)\n",
    "pyplot.hist(y, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "#pyplot.hist(y_pred, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Trained on ($p_e$, $p_{\\gamma}$, $\\omega_e$, $\\omega_{\\gamma}$, n)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample: 2971146 \n",
      "Valuation sample: 990383\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.75\n",
    "train_limit = int(len(y)*train_split)\n",
    "print(\"Training sample: {0} \\nValuation sample: {1}\".format(train_limit, len(y)-train_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:train_limit]\n",
    "x_val = x[train_limit:]\n",
    "\n",
    "y_train = y[:train_limit]\n",
    "y_val = y[train_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add (BatchNormalization(input_dim = 9))\n",
    "    model.add (layers.Dense (12 , activation = \"sigmoid\"))\n",
    "    model.add (layers.Dense (9 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (1 , activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\" , loss = 'mae' , metrics = [\"mape\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1729 - mape: 3602.3710 - val_loss: 0.1503 - val_mape: 3180.2134\n",
      "Epoch 2/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1246 - mape: 2827.7451 - val_loss: 0.1208 - val_mape: 2607.5073\n",
      "Epoch 3/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1077 - mape: 2282.8119 - val_loss: 0.1130 - val_mape: 2405.4766\n",
      "Epoch 4/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1021 - mape: 2104.9098 - val_loss: 0.1058 - val_mape: 2192.2456\n",
      "Epoch 5/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0996 - mape: 1967.0806 - val_loss: 0.1011 - val_mape: 1994.2059\n",
      "Epoch 6/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0972 - mape: 1838.9409 - val_loss: 0.0973 - val_mape: 1803.5790\n",
      "Epoch 7/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0945 - mape: 1691.7016 - val_loss: 0.0938 - val_mape: 1618.8070\n",
      "Epoch 8/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0917 - mape: 1540.5783 - val_loss: 0.0908 - val_mape: 1451.7228\n",
      "Epoch 9/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0889 - mape: 1393.8304 - val_loss: 0.0880 - val_mape: 1292.2271\n",
      "Epoch 10/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0862 - mape: 1247.7231 - val_loss: 0.0854 - val_mape: 1151.4945\n",
      "Epoch 11/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0837 - mape: 1114.5159 - val_loss: 0.0831 - val_mape: 1024.3356\n",
      "Epoch 12/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0813 - mape: 1001.0442 - val_loss: 0.0809 - val_mape: 908.4033\n",
      "Epoch 13/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0794 - mape: 890.8173 - val_loss: 0.0790 - val_mape: 816.9438\n",
      "Epoch 14/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0776 - mape: 795.9633 - val_loss: 0.0774 - val_mape: 732.9529\n",
      "Epoch 15/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0761 - mape: 717.4328 - val_loss: 0.0757 - val_mape: 659.3570\n",
      "Epoch 16/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0747 - mape: 645.7382 - val_loss: 0.0746 - val_mape: 597.5582\n",
      "Epoch 17/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0736 - mape: 584.0141 - val_loss: 0.0731 - val_mape: 543.8752\n",
      "Epoch 18/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0724 - mape: 532.3597 - val_loss: 0.0721 - val_mape: 497.1285\n",
      "Epoch 19/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0716 - mape: 489.0213 - val_loss: 0.0712 - val_mape: 457.1898\n",
      "Epoch 20/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0706 - mape: 446.4350 - val_loss: 0.0701 - val_mape: 419.7124\n",
      "Epoch 21/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0699 - mape: 415.3029 - val_loss: 0.0693 - val_mape: 393.4644\n",
      "Epoch 22/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0690 - mape: 388.0809 - val_loss: 0.0685 - val_mape: 365.8247\n",
      "Epoch 23/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0681 - mape: 362.3460 - val_loss: 0.0673 - val_mape: 349.0459\n",
      "Epoch 24/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0671 - mape: 343.3676 - val_loss: 0.0665 - val_mape: 325.4403\n",
      "Epoch 25/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0663 - mape: 321.9655 - val_loss: 0.0658 - val_mape: 309.1045\n",
      "Epoch 26/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0656 - mape: 304.1793 - val_loss: 0.0648 - val_mape: 291.3261\n",
      "Epoch 27/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0647 - mape: 285.6876 - val_loss: 0.0640 - val_mape: 273.7400\n",
      "Epoch 28/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0638 - mape: 270.5117 - val_loss: 0.0634 - val_mape: 257.3465\n",
      "Epoch 29/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0631 - mape: 256.6405 - val_loss: 0.0625 - val_mape: 247.8103\n",
      "Epoch 30/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0622 - mape: 244.1599 - val_loss: 0.0616 - val_mape: 234.7155\n",
      "Epoch 31/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0615 - mape: 232.3027 - val_loss: 0.0608 - val_mape: 225.1932\n",
      "Epoch 32/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0607 - mape: 221.2596 - val_loss: 0.0599 - val_mape: 212.7208\n",
      "Epoch 33/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0596 - mape: 211.1641 - val_loss: 0.0587 - val_mape: 206.3074\n",
      "Epoch 34/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0585 - mape: 205.0886 - val_loss: 0.0578 - val_mape: 201.1805\n",
      "Epoch 35/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0575 - mape: 199.6723 - val_loss: 0.0568 - val_mape: 195.1113\n",
      "Epoch 36/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0566 - mape: 191.9661 - val_loss: 0.0559 - val_mape: 189.0239\n",
      "Epoch 37/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0558 - mape: 186.9247 - val_loss: 0.0552 - val_mape: 183.8846\n",
      "Epoch 38/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0551 - mape: 182.2119 - val_loss: 0.0546 - val_mape: 177.5023\n",
      "Epoch 39/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0544 - mape: 176.6381 - val_loss: 0.0541 - val_mape: 174.2102\n",
      "Epoch 40/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0541 - mape: 171.7998 - val_loss: 0.0536 - val_mape: 168.6765\n",
      "Epoch 41/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0538 - mape: 167.6371 - val_loss: 0.0531 - val_mape: 163.9593\n",
      "Epoch 42/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0534 - mape: 163.3185 - val_loss: 0.0529 - val_mape: 158.9506\n",
      "Epoch 43/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0529 - mape: 158.2711 - val_loss: 0.0523 - val_mape: 156.5043\n",
      "Epoch 44/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0528 - mape: 154.4074 - val_loss: 0.0521 - val_mape: 152.0945\n",
      "Epoch 45/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0523 - mape: 149.4156 - val_loss: 0.0520 - val_mape: 149.3779\n",
      "Epoch 46/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0519 - mape: 146.5451 - val_loss: 0.0516 - val_mape: 143.5034\n",
      "Epoch 47/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0516 - mape: 142.9571 - val_loss: 0.0512 - val_mape: 141.4652\n",
      "Epoch 48/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0513 - mape: 140.6902 - val_loss: 0.0509 - val_mape: 137.4610\n",
      "Epoch 49/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0510 - mape: 135.9855 - val_loss: 0.0506 - val_mape: 132.9145\n",
      "Epoch 50/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0509 - mape: 132.3865 - val_loss: 0.0507 - val_mape: 129.5931\n",
      "Epoch 51/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0507 - mape: 129.5100 - val_loss: 0.0501 - val_mape: 127.8420\n",
      "Epoch 52/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0504 - mape: 126.8766 - val_loss: 0.0504 - val_mape: 126.1285\n",
      "Epoch 53/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0506 - mape: 123.9835 - val_loss: 0.0501 - val_mape: 123.3391\n",
      "Epoch 54/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0500 - mape: 121.4600 - val_loss: 0.0500 - val_mape: 121.5747\n",
      "Epoch 55/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0499 - mape: 117.8648 - val_loss: 0.0492 - val_mape: 117.1884\n",
      "Epoch 56/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0493 - mape: 115.9575 - val_loss: 0.0493 - val_mape: 113.9701\n",
      "Epoch 57/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0491 - mape: 114.0758 - val_loss: 0.0488 - val_mape: 113.4058\n",
      "Epoch 58/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0491 - mape: 112.8871 - val_loss: 0.0487 - val_mape: 110.2944\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0486 - mape: 110.2243 - val_loss: 0.0483 - val_mape: 108.1225\n",
      "Epoch 60/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0486 - mape: 107.6011 - val_loss: 0.0484 - val_mape: 105.6846\n",
      "Epoch 61/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0484 - mape: 106.1735 - val_loss: 0.0478 - val_mape: 105.1097\n",
      "Epoch 62/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0481 - mape: 103.8393 - val_loss: 0.0479 - val_mape: 101.4244\n",
      "Epoch 63/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0478 - mape: 101.8307 - val_loss: 0.0477 - val_mape: 99.9311\n",
      "Epoch 64/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0476 - mape: 99.8239 - val_loss: 0.0475 - val_mape: 97.6663\n",
      "Epoch 65/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0477 - mape: 98.6222 - val_loss: 0.0469 - val_mape: 97.1800\n",
      "Epoch 66/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0472 - mape: 97.2882 - val_loss: 0.0468 - val_mape: 97.2506\n",
      "Epoch 67/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0470 - mape: 95.7704 - val_loss: 0.0463 - val_mape: 95.7691\n",
      "Epoch 68/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0471 - mape: 95.5720 - val_loss: 0.0461 - val_mape: 93.9024\n",
      "Epoch 69/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0463 - mape: 93.3317 - val_loss: 0.0461 - val_mape: 92.5863\n",
      "Epoch 70/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0464 - mape: 92.1549 - val_loss: 0.0459 - val_mape: 90.0498\n",
      "Epoch 71/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0460 - mape: 90.0663 - val_loss: 0.0449 - val_mape: 90.5136\n",
      "Epoch 72/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0452 - mape: 89.7928 - val_loss: 0.0450 - val_mape: 88.1607\n",
      "Epoch 73/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0451 - mape: 89.0981 - val_loss: 0.0442 - val_mape: 87.4973\n",
      "Epoch 74/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0448 - mape: 87.3074 - val_loss: 0.0438 - val_mape: 86.5967\n",
      "Epoch 75/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0443 - mape: 86.3744 - val_loss: 0.0436 - val_mape: 85.9920\n",
      "Epoch 76/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0441 - mape: 84.8273 - val_loss: 0.0431 - val_mape: 84.1504\n",
      "Epoch 77/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0435 - mape: 83.4212 - val_loss: 0.0429 - val_mape: 83.5257\n",
      "Epoch 78/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0431 - mape: 82.3738 - val_loss: 0.0426 - val_mape: 82.0804\n",
      "Epoch 79/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0431 - mape: 81.4063 - val_loss: 0.0423 - val_mape: 80.9080\n",
      "Epoch 80/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0428 - mape: 80.9678 - val_loss: 0.0424 - val_mape: 80.3716\n",
      "Epoch 81/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0424 - mape: 79.9427 - val_loss: 0.0424 - val_mape: 78.3147\n",
      "Epoch 82/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0421 - mape: 78.5130 - val_loss: 0.0415 - val_mape: 77.3644\n",
      "Epoch 83/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0423 - mape: 78.2155 - val_loss: 0.0413 - val_mape: 76.9594\n",
      "Epoch 84/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0420 - mape: 75.8484 - val_loss: 0.0410 - val_mape: 75.7065\n",
      "Epoch 85/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0414 - mape: 75.6602 - val_loss: 0.0415 - val_mape: 76.1613\n",
      "Epoch 86/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0420 - mape: 74.8739 - val_loss: 0.0409 - val_mape: 74.0423\n",
      "Epoch 87/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0416 - mape: 74.5408 - val_loss: 0.0403 - val_mape: 72.2440\n",
      "Epoch 88/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0415 - mape: 72.7307 - val_loss: 0.0403 - val_mape: 72.6818\n",
      "Epoch 89/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0407 - mape: 72.2021 - val_loss: 0.0405 - val_mape: 70.7651\n",
      "Epoch 90/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0407 - mape: 71.6071 - val_loss: 0.0405 - val_mape: 71.6026\n",
      "Epoch 91/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0407 - mape: 71.1442 - val_loss: 0.0397 - val_mape: 68.9528\n",
      "Epoch 92/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0399 - mape: 69.4379 - val_loss: 0.0390 - val_mape: 68.8515\n",
      "Epoch 93/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0403 - mape: 69.3607 - val_loss: 0.0388 - val_mape: 67.9634\n",
      "Epoch 94/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0396 - mape: 68.4148 - val_loss: 0.0389 - val_mape: 67.8428\n",
      "Epoch 95/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0391 - mape: 67.2878 - val_loss: 0.0383 - val_mape: 66.2881\n",
      "Epoch 96/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0393 - mape: 66.6528 - val_loss: 0.0387 - val_mape: 65.0296\n",
      "Epoch 97/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0386 - mape: 65.6067 - val_loss: 0.0376 - val_mape: 64.2690\n",
      "Epoch 98/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0384 - mape: 65.3371 - val_loss: 0.0385 - val_mape: 66.8323\n",
      "Epoch 99/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0389 - mape: 65.1440 - val_loss: 0.0369 - val_mape: 63.2724\n",
      "Epoch 100/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0382 - mape: 64.3255 - val_loss: 0.0368 - val_mape: 62.8085\n",
      "Epoch 101/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0377 - mape: 63.4814 - val_loss: 0.0362 - val_mape: 63.1527\n",
      "Epoch 102/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0371 - mape: 63.0976 - val_loss: 0.0363 - val_mape: 61.3555\n",
      "Epoch 103/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0374 - mape: 62.7457 - val_loss: 0.0363 - val_mape: 60.7958\n",
      "Epoch 104/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0370 - mape: 62.1644 - val_loss: 0.0358 - val_mape: 62.3773\n",
      "Epoch 105/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0369 - mape: 62.2993 - val_loss: 0.0359 - val_mape: 62.7677\n",
      "Epoch 106/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0365 - mape: 62.1736 - val_loss: 0.0348 - val_mape: 60.9722\n",
      "Epoch 107/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0361 - mape: 61.1449 - val_loss: 0.0342 - val_mape: 60.1812\n",
      "Epoch 108/1000\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0363 - mape: 60.8158 - val_loss: 0.0343 - val_mape: 59.7542\n",
      "Epoch 109/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0356 - mape: 60.1147 - val_loss: 0.0342 - val_mape: 60.2282\n",
      "Epoch 110/1000\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0360 - mape: 60.0205 - val_loss: 0.0341 - val_mape: 58.6684\n",
      "Epoch 111/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0350 - mape: 59.3553 - val_loss: 0.0342 - val_mape: 58.0454\n",
      "Epoch 112/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0358 - mape: 58.9594 - val_loss: 0.0339 - val_mape: 59.4572\n",
      "Epoch 113/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0358 - mape: 59.7796 - val_loss: 0.0336 - val_mape: 58.5444\n",
      "Epoch 114/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0351 - mape: 59.0167 - val_loss: 0.0340 - val_mape: 57.9876\n",
      "Epoch 115/1000\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0348 - mape: 58.3510 - val_loss: 0.0335 - val_mape: 57.6449\n",
      "Epoch 116/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0341 - mape: 58.1324 - val_loss: 0.0328 - val_mape: 56.8169\n",
      "Epoch 117/1000\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0346 - mape: 57.8062 - val_loss: 0.0329 - val_mape: 57.2228\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0338 - mape: 57.3532 - val_loss: 0.0327 - val_mape: 55.9413\n",
      "Epoch 119/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0345 - mape: 57.0918 - val_loss: 0.0324 - val_mape: 55.8026\n",
      "Epoch 120/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0337 - mape: 56.4648 - val_loss: 0.0331 - val_mape: 56.9529\n",
      "Epoch 121/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0338 - mape: 56.4003 - val_loss: 0.0325 - val_mape: 55.2050\n",
      "Epoch 122/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0342 - mape: 55.9332 - val_loss: 0.0323 - val_mape: 54.5343\n",
      "Epoch 123/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0347 - mape: 56.2837 - val_loss: 0.0325 - val_mape: 54.7508\n",
      "Epoch 124/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0337 - mape: 56.0422 - val_loss: 0.0317 - val_mape: 54.0859\n",
      "Epoch 125/1000\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0336 - mape: 55.6116 - val_loss: 0.0344 - val_mape: 53.1631\n",
      "Epoch 126/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0347 - mape: 54.4106 - val_loss: 0.0316 - val_mape: 53.3754\n",
      "Epoch 127/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0327 - mape: 54.1787 - val_loss: 0.0318 - val_mape: 52.7717\n",
      "Epoch 128/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0337 - mape: 54.8864 - val_loss: 0.0318 - val_mape: 53.7662\n",
      "Epoch 129/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0329 - mape: 53.3166 - val_loss: 0.0316 - val_mape: 53.2558\n",
      "Epoch 130/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0326 - mape: 53.6023 - val_loss: 0.0319 - val_mape: 53.1665\n",
      "Epoch 131/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0331 - mape: 53.5021 - val_loss: 0.0314 - val_mape: 52.2916\n",
      "Epoch 132/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0323 - mape: 53.0593 - val_loss: 0.0307 - val_mape: 51.8484\n",
      "Epoch 133/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0321 - mape: 52.5530 - val_loss: 0.0308 - val_mape: 52.1089\n",
      "Epoch 134/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0328 - mape: 52.8208 - val_loss: 0.0304 - val_mape: 51.4846\n",
      "Epoch 135/1000\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0320 - mape: 51.9650 - val_loss: 0.0307 - val_mape: 51.0990\n",
      "Epoch 136/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0324 - mape: 52.0478 - val_loss: 0.0304 - val_mape: 50.9568\n",
      "Epoch 137/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0317 - mape: 51.5306 - val_loss: 0.0300 - val_mape: 50.6138\n",
      "Epoch 138/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0313 - mape: 50.7461 - val_loss: 0.0295 - val_mape: 49.6156\n",
      "Epoch 139/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0314 - mape: 51.1632 - val_loss: 0.0303 - val_mape: 49.8995\n",
      "Epoch 140/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0313 - mape: 50.0019 - val_loss: 0.0307 - val_mape: 49.8164\n",
      "Epoch 141/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0315 - mape: 50.0228 - val_loss: 0.0299 - val_mape: 49.6245\n",
      "Epoch 142/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0312 - mape: 50.1695 - val_loss: 0.0294 - val_mape: 48.3033\n",
      "Epoch 143/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0307 - mape: 49.5912 - val_loss: 0.0298 - val_mape: 49.2075\n",
      "Epoch 144/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0312 - mape: 49.8532 - val_loss: 0.0300 - val_mape: 47.6771\n",
      "Epoch 145/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0311 - mape: 49.4040 - val_loss: 0.0288 - val_mape: 48.1011\n",
      "Epoch 146/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0317 - mape: 49.7566 - val_loss: 0.0297 - val_mape: 48.4389\n",
      "Epoch 147/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0314 - mape: 49.3006 - val_loss: 0.0288 - val_mape: 47.8698\n",
      "Epoch 148/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0308 - mape: 48.8044 - val_loss: 0.0297 - val_mape: 48.8262\n",
      "Epoch 149/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0326 - mape: 49.6266 - val_loss: 0.0288 - val_mape: 47.8084\n",
      "Epoch 150/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0297 - mape: 48.0100 - val_loss: 0.0292 - val_mape: 48.1365\n",
      "Epoch 151/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0303 - mape: 48.4255 - val_loss: 0.0292 - val_mape: 46.9028\n",
      "Epoch 152/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0319 - mape: 48.3084 - val_loss: 0.0285 - val_mape: 46.3521\n",
      "Epoch 153/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0299 - mape: 47.9674 - val_loss: 0.0282 - val_mape: 46.5547\n",
      "Epoch 154/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0299 - mape: 47.7419 - val_loss: 0.0280 - val_mape: 46.0217\n",
      "Epoch 155/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0298 - mape: 47.3024 - val_loss: 0.0281 - val_mape: 46.3020\n",
      "Epoch 156/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0308 - mape: 47.2851 - val_loss: 0.0285 - val_mape: 45.5136\n",
      "Epoch 157/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0294 - mape: 46.6555 - val_loss: 0.0279 - val_mape: 45.1739\n",
      "Epoch 158/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0288 - mape: 46.1409 - val_loss: 0.0277 - val_mape: 45.5708\n",
      "Epoch 159/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0287 - mape: 45.9828 - val_loss: 0.0275 - val_mape: 44.8736\n",
      "Epoch 160/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0288 - mape: 46.3701 - val_loss: 0.0275 - val_mape: 45.4660\n",
      "Epoch 161/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0308 - mape: 47.2181 - val_loss: 0.0281 - val_mape: 45.2164\n",
      "Epoch 162/1000\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0304 - mape: 46.7531 - val_loss: 0.0284 - val_mape: 45.3938\n",
      "Epoch 163/1000\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0293 - mape: 46.1163 - val_loss: 0.0273 - val_mape: 44.4160\n",
      "Epoch 164/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0288 - mape: 45.3947 - val_loss: 0.0276 - val_mape: 44.6458\n",
      "Epoch 165/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0299 - mape: 45.7625 - val_loss: 0.0282 - val_mape: 45.2470\n",
      "Epoch 166/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0285 - mape: 45.4587 - val_loss: 0.0274 - val_mape: 44.5770\n",
      "Epoch 167/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0295 - mape: 45.7242 - val_loss: 0.0281 - val_mape: 44.7448\n",
      "Epoch 168/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0293 - mape: 45.3652 - val_loss: 0.0271 - val_mape: 44.2833\n",
      "Epoch 169/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0288 - mape: 45.0128 - val_loss: 0.0272 - val_mape: 44.2361\n",
      "Epoch 170/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0285 - mape: 44.7486 - val_loss: 0.0270 - val_mape: 44.2050\n",
      "Epoch 171/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0297 - mape: 45.3237 - val_loss: 0.0271 - val_mape: 44.2830\n",
      "Epoch 172/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0291 - mape: 44.8403 - val_loss: 0.0266 - val_mape: 43.5143\n",
      "Epoch 173/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0285 - mape: 44.4323 - val_loss: 0.0270 - val_mape: 43.6284\n",
      "Epoch 174/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0281 - mape: 44.4396 - val_loss: 0.0268 - val_mape: 42.7377\n",
      "Epoch 175/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0287 - mape: 44.5086 - val_loss: 0.0266 - val_mape: 43.4856\n",
      "Epoch 176/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0284 - mape: 44.3384 - val_loss: 0.0265 - val_mape: 43.1485\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0280 - mape: 43.9908 - val_loss: 0.0262 - val_mape: 42.9153\n",
      "Epoch 178/1000\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0279 - mape: 43.5739 - val_loss: 0.0263 - val_mape: 42.9659\n",
      "Epoch 179/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0275 - mape: 43.7085 - val_loss: 0.0267 - val_mape: 43.1481\n",
      "Epoch 180/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0283 - mape: 43.8081 - val_loss: 0.0260 - val_mape: 42.5537\n",
      "Epoch 181/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0284 - mape: 43.7640 - val_loss: 0.0270 - val_mape: 42.6201\n",
      "Epoch 182/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0286 - mape: 43.7394 - val_loss: 0.0265 - val_mape: 42.2335\n",
      "Epoch 183/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0280 - mape: 43.1954 - val_loss: 0.0271 - val_mape: 41.6818\n",
      "Epoch 184/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0287 - mape: 43.0952 - val_loss: 0.0265 - val_mape: 42.6083\n",
      "Epoch 185/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0278 - mape: 43.2457 - val_loss: 0.0260 - val_mape: 42.4171\n",
      "Epoch 186/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0274 - mape: 42.7655 - val_loss: 0.0261 - val_mape: 41.5748\n",
      "Epoch 187/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0278 - mape: 43.0650 - val_loss: 0.0253 - val_mape: 41.5969\n",
      "Epoch 188/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0297 - mape: 43.6925 - val_loss: 0.0267 - val_mape: 41.9273\n",
      "Epoch 189/1000\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0279 - mape: 42.1739 - val_loss: 0.0253 - val_mape: 41.2718\n",
      "Epoch 190/1000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0277 - mape: 42.6837 - val_loss: 0.0253 - val_mape: 41.0325\n",
      "Epoch 191/1000\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0267 - mape: 42.4986"
     ]
    }
   ],
   "source": [
    "model = build_model ()\n",
    "history = model.fit ( x_train, y_train, epochs = 1000, batch_size = 100000 , validation_data = (x_val, y_val) )\n",
    "model.save(\"../models/classifier/{}_noposition2.h5\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "accuracy = history.history['mape']\n",
    "val_accuracy = history.history['val_mape']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "l1 = ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "vl1 = ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss (mae))')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ac2= ax2.plot(epochs, accuracy, 'o', c=\"red\", label='Training acc')\n",
    "vac2= ax2.plot(epochs, val_accuracy, 'r', label='Validation acc')\n",
    "ax2.set_ylabel('mape')\n",
    "\n",
    "lns = l1 + vl1 + ac2 + vac2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=\"center right\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"acc+loss_drop.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = class_data0[:,0]\n",
    "A0 = class_data0\n",
    "A0[:,9] = A0[:,13]\n",
    "x0 = class_data0[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "y = np.array(y)\n",
    "bins = np.linspace(0, 0.8, 100)\n",
    "pyplot.hist(y0, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "pyplot.hist(y_pred, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Trained on ($p_e$, $p_{\\gamma}$, $\\omega_e$, $\\omega_{\\gamma}$, n)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
