{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "print(pd.__version__)\n",
    "import progressbar\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Dependencies\n",
    "\n",
    "\n",
    "\n",
    "Dependences are fundamental to record the computational environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.5\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "pandas    : 1.2.3\n",
      "keras     : 2.4.3\n",
      "numpy     : 1.19.5\n",
      "math      : unknown\n",
      "tensorflow: 2.4.1\n",
      "matplotlib: 3.3.4\n",
      "h5py      : 2.10.0\n",
      "\n",
      "Compiler    : GCC 9.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.8.0-48-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      " \n",
      "Last updated: Mon Mar 29 2021 19:25:30CEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p pandas,keras,numpy,math,tensorflow,matplotlib,h5py\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of the data\n",
    "\n",
    "   You can also load all of them! Writing \"all_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import loaddata\n",
    "class_data = loaddata(\"../data/{}.csv\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = class_data[class_data[:,0] > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135911, 9)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(class_data)\n",
    "y = class_data[:,0]\n",
    "A = class_data\n",
    "A[:,7:10] = A[:,11:14]\n",
    "x = class_data[:,1:10]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 11, 12, 13, 10, 11, 12, 13]\n",
      "[11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "prova = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "a = prova\n",
    "a[7:10] = a [11:14]\n",
    "print(a)\n",
    "#I want to remove [7,8,9,10] that are the positions\n",
    "b = prova[11:14]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample: 101933 \n",
      "Valuation sample: 33978\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.75\n",
    "train_limit = int(len(y)*train_split)\n",
    "print(\"Training sample: {0} \\nValuation sample: {1}\".format(train_limit, len(y)-train_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:train_limit]\n",
    "x_val = x[train_limit:]\n",
    "\n",
    "y_train = y[:train_limit]\n",
    "y_val = y[train_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add (BatchNormalization(input_dim = 9))\n",
    "    model.add (layers.Dense (18 , activation = \"sigmoid\"))\n",
    "    model.add (layers.Dense (36, activation = \"relu\"))\n",
    "    model.add (layers.Dense (72 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (144 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (72, activation = \"relu\"))\n",
    "    model.add (layers.Dense (36 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (18, activation = \"relu\"))\n",
    "    model.add (layers.Dense (9 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (1 , activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\" , loss = \"mape\" , metrics = [\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 740.4548 - mae: 0.3180 - val_loss: 708.0137 - val_mae: 0.3023\n",
      "Epoch 2/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 717.6538 - mae: 0.3042 - val_loss: 691.3784 - val_mae: 0.2927\n",
      "Epoch 3/20000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 699.7462 - mae: 0.2937 - val_loss: 677.0361 - val_mae: 0.2846\n",
      "Epoch 4/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 684.3220 - mae: 0.2849 - val_loss: 660.9215 - val_mae: 0.2755\n",
      "Epoch 5/20000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 667.1882 - mae: 0.2750 - val_loss: 642.6736 - val_mae: 0.2650\n",
      "Epoch 6/20000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 648.4995 - mae: 0.2642 - val_loss: 621.3582 - val_mae: 0.2526\n",
      "Epoch 7/20000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 626.8519 - mae: 0.2517 - val_loss: 596.8683 - val_mae: 0.2383\n",
      "Epoch 8/20000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 601.6803 - mae: 0.2370 - val_loss: 567.5952 - val_mae: 0.2211\n",
      "Epoch 9/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 571.9003 - mae: 0.2196 - val_loss: 533.1063 - val_mae: 0.2009\n",
      "Epoch 10/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 537.0392 - mae: 0.1994 - val_loss: 493.9719 - val_mae: 0.1782\n",
      "Epoch 11/20000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 497.5583 - mae: 0.1766 - val_loss: 452.8881 - val_mae: 0.1548\n",
      "Epoch 12/20000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 455.3105 - mae: 0.1528 - val_loss: 408.1992 - val_mae: 0.1303\n",
      "Epoch 13/20000\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 409.7711 - mae: 0.1280 - val_loss: 359.4679 - val_mae: 0.1055\n",
      "Epoch 14/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 360.5335 - mae: 0.1037 - val_loss: 308.8652 - val_mae: 0.0850\n",
      "Epoch 15/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 309.7610 - mae: 0.0841 - val_loss: 259.8080 - val_mae: 0.0736\n",
      "Epoch 16/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 260.6115 - mae: 0.0738 - val_loss: 215.5228 - val_mae: 0.0732\n",
      "Epoch 17/20000\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 216.1871 - mae: 0.0740 - val_loss: 178.7923 - val_mae: 0.0819\n",
      "Epoch 18/20000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 178.9605 - mae: 0.0832 - val_loss: 149.1333 - val_mae: 0.0966\n",
      "Epoch 19/20000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 149.1460 - mae: 0.0981 - val_loss: 126.6906 - val_mae: 0.1139\n",
      "Epoch 20/20000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 126.7283 - mae: 0.1154 - val_loss: 111.2746 - val_mae: 0.1308\n",
      "Epoch 21/20000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 111.3539 - mae: 0.1321 - val_loss: 101.8932 - val_mae: 0.1454\n",
      "Epoch 22/20000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 102.0209 - mae: 0.1464 - val_loss: 97.0425 - val_mae: 0.1569\n",
      "Epoch 23/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 97.1643 - mae: 0.1575 - val_loss: 95.1513 - val_mae: 0.1654\n",
      "Epoch 24/20000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 95.2466 - mae: 0.1657 - val_loss: 94.9012 - val_mae: 0.1712\n",
      "Epoch 25/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 94.9649 - mae: 0.1712 - val_loss: 95.3685 - val_mae: 0.1751\n",
      "Epoch 26/20000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 95.4182 - mae: 0.1749 - val_loss: 96.1170 - val_mae: 0.1776\n",
      "Epoch 27/20000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 96.1138 - mae: 0.1773 - val_loss: 96.8221 - val_mae: 0.1793\n",
      "Epoch 28/20000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 96.8178 - mae: 0.1789 - val_loss: 97.4312 - val_mae: 0.1804\n",
      "Epoch 29/20000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 97.4308 - mae: 0.1799 - val_loss: 97.9182 - val_mae: 0.1811\n",
      "Epoch 30/20000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 97.9596 - mae: 0.1805 - val_loss: 98.3376 - val_mae: 0.1815\n",
      "Epoch 31/20000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 98.4120 - mae: 0.1810 - val_loss: 98.7098 - val_mae: 0.1819\n",
      "Epoch 32/20000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 98.7828 - mae: 0.1813 - val_loss: 99.0065 - val_mae: 0.1821\n",
      "Epoch 33/20000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 99.0644 - mae: 0.1815 - val_loss: 99.2257 - val_mae: 0.1822\n",
      "Epoch 34/20000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 99.2660 - mae: 0.1816 - val_loss: 99.3832 - val_mae: 0.1823\n",
      "Epoch 35/20000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 99.4118 - mae: 0.1817 - val_loss: 99.4976 - val_mae: 0.1824\n",
      "Epoch 36/20000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 99.5190 - mae: 0.1818 - val_loss: 99.5822 - val_mae: 0.1825\n",
      "Epoch 37/20000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 99.5998 - mae: 0.1818 - val_loss: 99.6479 - val_mae: 0.1825\n",
      "Epoch 38/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 99.6619 - mae: 0.1819 - val_loss: 99.6991 - val_mae: 0.1826\n",
      "Epoch 39/20000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 99.7104 - mae: 0.1819 - val_loss: 99.7388 - val_mae: 0.1826\n",
      "Epoch 40/20000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 99.7486 - mae: 0.1819 - val_loss: 99.7700 - val_mae: 0.1826\n",
      "Epoch 41/20000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 99.7792 - mae: 0.1820 - val_loss: 99.7948 - val_mae: 0.1826\n",
      "Epoch 42/20000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 99.8035 - mae: 0.1820 - val_loss: 99.8147 - val_mae: 0.1826\n",
      "Epoch 43/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 99.8233 - mae: 0.1820 - val_loss: 99.8308 - val_mae: 0.1827\n",
      "Epoch 44/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 99.8394 - mae: 0.1820 - val_loss: 99.8440 - val_mae: 0.1827\n",
      "Epoch 45/20000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 99.8526 - mae: 0.1820 - val_loss: 99.8549 - val_mae: 0.1827\n",
      "Epoch 46/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 99.8636 - mae: 0.1820 - val_loss: 99.8638 - val_mae: 0.1827\n",
      "Epoch 47/20000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 99.8727 - mae: 0.1820 - val_loss: 99.8713 - val_mae: 0.1827\n",
      "Epoch 48/20000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 99.8802 - mae: 0.1820 - val_loss: 99.8778 - val_mae: 0.1827\n",
      "Epoch 49/20000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 99.8865 - mae: 0.1820 - val_loss: 99.8832 - val_mae: 0.1827\n",
      "Epoch 50/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 99.8918 - mae: 0.1820 - val_loss: 99.8878 - val_mae: 0.1827\n",
      "Epoch 51/20000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 99.8961 - mae: 0.1820 - val_loss: 99.8916 - val_mae: 0.1827\n",
      "Epoch 52/20000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 99.8998 - mae: 0.1820 - val_loss: 99.8950 - val_mae: 0.1827\n",
      "Epoch 53/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 99.9028 - mae: 0.1820 - val_loss: 99.8977 - val_mae: 0.1827\n",
      "Epoch 54/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 99.9054 - mae: 0.1820 - val_loss: 99.9000 - val_mae: 0.1827\n",
      "Epoch 55/20000\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 99.9074 - mae: 0.1820 - val_loss: 99.9018 - val_mae: 0.1827\n",
      "Epoch 56/20000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 99.9090 - mae: 0.1820 - val_loss: 99.9032 - val_mae: 0.1827\n",
      "Epoch 57/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 99.9103 - mae: 0.1820 - val_loss: 99.9044 - val_mae: 0.1827\n",
      "Epoch 58/20000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 99.9113 - mae: 0.1820 - val_loss: 99.9051 - val_mae: 0.1827\n",
      "Epoch 59/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 99.9120 - mae: 0.1820 - val_loss: 99.9057 - val_mae: 0.1827\n",
      "Epoch 60/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 99.9124 - mae: 0.1820 - val_loss: 99.9059 - val_mae: 0.1827\n",
      "Epoch 61/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step - loss: 99.9126 - mae: 0.1820 - val_loss: 99.9059 - val_mae: 0.1827\n",
      "Epoch 62/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 99.9125 - mae: 0.1820 - val_loss: 99.9057 - val_mae: 0.1827\n",
      "Epoch 63/20000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 99.9123 - mae: 0.1820 - val_loss: 99.9053 - val_mae: 0.1827\n",
      "Epoch 64/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 99.9118 - mae: 0.1820 - val_loss: 99.9047 - val_mae: 0.1827\n",
      "Epoch 65/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 99.9111 - mae: 0.1820 - val_loss: 99.9039 - val_mae: 0.1827\n",
      "Epoch 66/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 99.9103 - mae: 0.1820 - val_loss: 99.9029 - val_mae: 0.1827\n",
      "Epoch 67/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 99.9093 - mae: 0.1820 - val_loss: 99.9017 - val_mae: 0.1827\n",
      "Epoch 68/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 99.9081 - mae: 0.1820 - val_loss: 99.9003 - val_mae: 0.1827\n",
      "Epoch 69/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 99.9067 - mae: 0.1820 - val_loss: 99.8987 - val_mae: 0.1827\n",
      "Epoch 70/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 99.9051 - mae: 0.1820 - val_loss: 99.8970 - val_mae: 0.1827\n",
      "Epoch 71/20000\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 99.9034 - mae: 0.1820 - val_loss: 99.8950 - val_mae: 0.1827\n",
      "Epoch 72/20000\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 99.9014 - mae: 0.1820 - val_loss: 99.8928 - val_mae: 0.1827\n",
      "Epoch 73/20000\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 99.8993 - mae: 0.1820 - val_loss: 99.8904 - val_mae: 0.1827\n",
      "Epoch 74/20000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 99.8969 - mae: 0.1820 - val_loss: 99.8878 - val_mae: 0.1827\n",
      "Epoch 75/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 99.8944 - mae: 0.1820 - val_loss: 99.8850 - val_mae: 0.1827\n",
      "Epoch 76/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 99.8916 - mae: 0.1820 - val_loss: 99.8820 - val_mae: 0.1827\n",
      "Epoch 77/20000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 99.8886 - mae: 0.1820 - val_loss: 99.8789 - val_mae: 0.1827\n",
      "Epoch 78/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 99.8853 - mae: 0.1820 - val_loss: 99.8755 - val_mae: 0.1827\n",
      "Epoch 79/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 99.8818 - mae: 0.1820 - val_loss: 99.8718 - val_mae: 0.1827\n",
      "Epoch 80/20000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 99.8780 - mae: 0.1820 - val_loss: 99.8678 - val_mae: 0.1827\n",
      "Epoch 81/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 99.8738 - mae: 0.1820 - val_loss: 99.8635 - val_mae: 0.1827\n",
      "Epoch 82/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 99.8694 - mae: 0.1820 - val_loss: 99.8588 - val_mae: 0.1827\n",
      "Epoch 83/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 99.8646 - mae: 0.1820 - val_loss: 99.8538 - val_mae: 0.1827\n",
      "Epoch 84/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 99.8594 - mae: 0.1820 - val_loss: 99.8483 - val_mae: 0.1827\n",
      "Epoch 85/20000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 99.8538 - mae: 0.1820 - val_loss: 99.8426 - val_mae: 0.1827\n",
      "Epoch 86/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 99.8477 - mae: 0.1820 - val_loss: 99.8363 - val_mae: 0.1827\n",
      "Epoch 87/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 99.8412 - mae: 0.1820 - val_loss: 99.8296 - val_mae: 0.1827\n",
      "Epoch 88/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 99.8342 - mae: 0.1820 - val_loss: 99.8223 - val_mae: 0.1827\n",
      "Epoch 89/20000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 99.8266 - mae: 0.1820 - val_loss: 99.8143 - val_mae: 0.1826\n",
      "Epoch 90/20000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 99.8184 - mae: 0.1820 - val_loss: 99.8057 - val_mae: 0.1826\n",
      "Epoch 91/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 99.8095 - mae: 0.1820 - val_loss: 99.7963 - val_mae: 0.1826\n",
      "Epoch 92/20000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 99.7998 - mae: 0.1820 - val_loss: 99.7860 - val_mae: 0.1826\n",
      "Epoch 93/20000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 99.7893 - mae: 0.1820 - val_loss: 99.7748 - val_mae: 0.1826\n",
      "Epoch 94/20000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 99.7779 - mae: 0.1820 - val_loss: 99.7626 - val_mae: 0.1826\n",
      "Epoch 95/20000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 99.7654 - mae: 0.1820 - val_loss: 99.7492 - val_mae: 0.1826\n",
      "Epoch 96/20000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 99.7518 - mae: 0.1819 - val_loss: 99.7345 - val_mae: 0.1826\n",
      "Epoch 97/20000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 99.7371 - mae: 0.1819 - val_loss: 99.7183 - val_mae: 0.1826\n",
      "Epoch 98/20000\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 99.7210 - mae: 0.1819 - val_loss: 99.7005 - val_mae: 0.1826\n",
      "Epoch 99/20000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 99.7033 - mae: 0.1819 - val_loss: 99.6809 - val_mae: 0.1826\n",
      "Epoch 100/20000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 99.6840 - mae: 0.1819 - val_loss: 99.6591 - val_mae: 0.1825\n",
      "Epoch 101/20000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 99.6627 - mae: 0.1819 - val_loss: 99.6354 - val_mae: 0.1825\n",
      "Epoch 102/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 99.6392 - mae: 0.1819 - val_loss: 99.6093 - val_mae: 0.1825\n",
      "Epoch 103/20000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 99.6131 - mae: 0.1819 - val_loss: 99.5802 - val_mae: 0.1825\n",
      "Epoch 104/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 99.5842 - mae: 0.1818 - val_loss: 99.5479 - val_mae: 0.1825\n",
      "Epoch 105/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 99.5522 - mae: 0.1818 - val_loss: 99.5120 - val_mae: 0.1824\n",
      "Epoch 106/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 99.5163 - mae: 0.1818 - val_loss: 99.4716 - val_mae: 0.1824\n",
      "Epoch 107/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 99.4763 - mae: 0.1818 - val_loss: 99.4260 - val_mae: 0.1824\n",
      "Epoch 108/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 99.4318 - mae: 0.1817 - val_loss: 99.3743 - val_mae: 0.1823\n",
      "Epoch 109/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 99.3820 - mae: 0.1817 - val_loss: 99.3156 - val_mae: 0.1823\n",
      "Epoch 110/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 99.3256 - mae: 0.1817 - val_loss: 99.2485 - val_mae: 0.1823\n",
      "Epoch 111/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 99.2614 - mae: 0.1816 - val_loss: 99.1719 - val_mae: 0.1822\n",
      "Epoch 112/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 99.1882 - mae: 0.1816 - val_loss: 99.0845 - val_mae: 0.1822\n",
      "Epoch 113/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 99.1052 - mae: 0.1815 - val_loss: 98.9854 - val_mae: 0.1821\n",
      "Epoch 114/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 99.0106 - mae: 0.1815 - val_loss: 98.8728 - val_mae: 0.1820\n",
      "Epoch 115/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 98.9026 - mae: 0.1814 - val_loss: 98.7470 - val_mae: 0.1819\n",
      "Epoch 116/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 98.7787 - mae: 0.1813 - val_loss: 98.6070 - val_mae: 0.1818\n",
      "Epoch 117/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 98.6385 - mae: 0.1812 - val_loss: 98.4547 - val_mae: 0.1817\n",
      "Epoch 118/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 98.4829 - mae: 0.1811 - val_loss: 98.2919 - val_mae: 0.1815\n",
      "Epoch 119/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 98.3105 - mae: 0.1809 - val_loss: 98.1292 - val_mae: 0.1814\n",
      "Epoch 120/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 98.1366 - mae: 0.1808 - val_loss: 97.9903 - val_mae: 0.1812\n",
      "Epoch 121/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 243ms/step - loss: 97.9852 - mae: 0.1806 - val_loss: 97.8423 - val_mae: 0.1810\n",
      "Epoch 122/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 97.8243 - mae: 0.1804 - val_loss: 97.6857 - val_mae: 0.1808\n",
      "Epoch 123/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 97.6541 - mae: 0.1802 - val_loss: 97.5192 - val_mae: 0.1806\n",
      "Epoch 124/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 97.4761 - mae: 0.1800 - val_loss: 97.3438 - val_mae: 0.1803\n",
      "Epoch 125/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 97.2890 - mae: 0.1798 - val_loss: 97.1539 - val_mae: 0.1800\n",
      "Epoch 126/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 97.0918 - mae: 0.1795 - val_loss: 96.9483 - val_mae: 0.1797\n",
      "Epoch 127/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 96.8822 - mae: 0.1791 - val_loss: 96.7242 - val_mae: 0.1793\n",
      "Epoch 128/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 96.6561 - mae: 0.1788 - val_loss: 96.4869 - val_mae: 0.1788\n",
      "Epoch 129/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 96.4135 - mae: 0.1783 - val_loss: 96.2385 - val_mae: 0.1783\n",
      "Epoch 130/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 96.1574 - mae: 0.1778 - val_loss: 95.9715 - val_mae: 0.1776\n",
      "Epoch 131/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 95.8917 - mae: 0.1772 - val_loss: 95.6888 - val_mae: 0.1769\n",
      "Epoch 132/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 95.6253 - mae: 0.1764 - val_loss: 95.4061 - val_mae: 0.1760\n",
      "Epoch 133/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 95.3594 - mae: 0.1756 - val_loss: 95.1380 - val_mae: 0.1750\n",
      "Epoch 134/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 95.1087 - mae: 0.1747 - val_loss: 94.8966 - val_mae: 0.1739\n",
      "Epoch 135/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 94.8826 - mae: 0.1736 - val_loss: 94.7013 - val_mae: 0.1727\n",
      "Epoch 136/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 94.6889 - mae: 0.1725 - val_loss: 94.5505 - val_mae: 0.1713\n",
      "Epoch 137/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 94.5330 - mae: 0.1712 - val_loss: 94.4504 - val_mae: 0.1699\n",
      "Epoch 138/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 94.4319 - mae: 0.1699 - val_loss: 94.4145 - val_mae: 0.1685\n",
      "Epoch 139/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 94.3843 - mae: 0.1685 - val_loss: 94.4285 - val_mae: 0.1671\n",
      "Epoch 140/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 94.3807 - mae: 0.1673 - val_loss: 94.4656 - val_mae: 0.1660\n",
      "Epoch 141/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 94.3971 - mae: 0.1664 - val_loss: 94.4887 - val_mae: 0.1653\n",
      "Epoch 142/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 94.4030 - mae: 0.1658 - val_loss: 94.4729 - val_mae: 0.1651\n",
      "Epoch 143/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 94.3760 - mae: 0.1656 - val_loss: 94.3941 - val_mae: 0.1654\n",
      "Epoch 144/20000\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 94.3145 - mae: 0.1659 - val_loss: 94.2854 - val_mae: 0.1662\n",
      "Epoch 145/20000\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 94.2328 - mae: 0.1665 - val_loss: 94.1907 - val_mae: 0.1672\n",
      "Epoch 146/20000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 94.1650 - mae: 0.1674 - val_loss: 94.1350 - val_mae: 0.1683\n",
      "Epoch 147/20000\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 94.1244 - mae: 0.1684 - val_loss: 94.1215 - val_mae: 0.1692\n",
      "Epoch 148/20000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 94.1160 - mae: 0.1693 - val_loss: 94.1194 - val_mae: 0.1698\n",
      "Epoch 149/20000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 94.1171 - mae: 0.1699 - val_loss: 94.1065 - val_mae: 0.1701\n",
      "Epoch 150/20000\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 94.1065 - mae: 0.1702 - val_loss: 94.0744 - val_mae: 0.1700\n",
      "Epoch 151/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 94.0752 - mae: 0.1701 - val_loss: 94.0252 - val_mae: 0.1696\n",
      "Epoch 152/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 94.0246 - mae: 0.1698 - val_loss: 93.9685 - val_mae: 0.1690\n",
      "Epoch 153/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 93.9642 - mae: 0.1692 - val_loss: 93.9167 - val_mae: 0.1682\n",
      "Epoch 154/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.9067 - mae: 0.1685 - val_loss: 93.8817 - val_mae: 0.1673\n",
      "Epoch 155/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 93.8618 - mae: 0.1677 - val_loss: 93.8608 - val_mae: 0.1665\n",
      "Epoch 156/20000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 93.8289 - mae: 0.1670 - val_loss: 93.8433 - val_mae: 0.1659\n",
      "Epoch 157/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 93.7980 - mae: 0.1666 - val_loss: 93.8113 - val_mae: 0.1658\n",
      "Epoch 158/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 93.7626 - mae: 0.1666 - val_loss: 93.7689 - val_mae: 0.1660\n",
      "Epoch 159/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 93.7225 - mae: 0.1669 - val_loss: 93.7243 - val_mae: 0.1663\n",
      "Epoch 160/20000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 93.6892 - mae: 0.1673 - val_loss: 93.6895 - val_mae: 0.1667\n",
      "Epoch 161/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 93.6639 - mae: 0.1677 - val_loss: 93.6681 - val_mae: 0.1669\n",
      "Epoch 162/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 93.6424 - mae: 0.1679 - val_loss: 93.6451 - val_mae: 0.1667\n",
      "Epoch 163/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 93.6162 - mae: 0.1678 - val_loss: 93.6255 - val_mae: 0.1663\n",
      "Epoch 164/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 93.5875 - mae: 0.1675 - val_loss: 93.6117 - val_mae: 0.1658\n",
      "Epoch 165/20000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 93.5615 - mae: 0.1670 - val_loss: 93.6023 - val_mae: 0.1653\n",
      "Epoch 166/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 93.5410 - mae: 0.1665 - val_loss: 93.5912 - val_mae: 0.1650\n",
      "Epoch 167/20000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 93.5219 - mae: 0.1663 - val_loss: 93.5677 - val_mae: 0.1650\n",
      "Epoch 168/20000\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 93.4999 - mae: 0.1663 - val_loss: 93.5352 - val_mae: 0.1653\n",
      "Epoch 169/20000\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 93.4762 - mae: 0.1665 - val_loss: 93.5058 - val_mae: 0.1657\n",
      "Epoch 170/20000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 93.4561 - mae: 0.1669 - val_loss: 93.4838 - val_mae: 0.1660\n",
      "Epoch 171/20000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 93.4405 - mae: 0.1671 - val_loss: 93.4665 - val_mae: 0.1661\n",
      "Epoch 172/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 93.4252 - mae: 0.1672 - val_loss: 93.4535 - val_mae: 0.1659\n",
      "Epoch 173/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 93.4070 - mae: 0.1671 - val_loss: 93.4439 - val_mae: 0.1656\n",
      "Epoch 174/20000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 93.3886 - mae: 0.1667 - val_loss: 93.4383 - val_mae: 0.1652\n",
      "Epoch 175/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 93.3726 - mae: 0.1664 - val_loss: 93.4311 - val_mae: 0.1649\n",
      "Epoch 176/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 93.3593 - mae: 0.1661 - val_loss: 93.4173 - val_mae: 0.1648\n",
      "Epoch 177/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 93.3449 - mae: 0.1660 - val_loss: 93.3959 - val_mae: 0.1650\n",
      "Epoch 178/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 93.3296 - mae: 0.1661 - val_loss: 93.3726 - val_mae: 0.1652\n",
      "Epoch 179/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 93.3151 - mae: 0.1663 - val_loss: 93.3535 - val_mae: 0.1655\n",
      "Epoch 180/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 93.3031 - mae: 0.1665 - val_loss: 93.3396 - val_mae: 0.1656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 93.2925 - mae: 0.1666 - val_loss: 93.3305 - val_mae: 0.1655\n",
      "Epoch 182/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 93.2810 - mae: 0.1665 - val_loss: 93.3268 - val_mae: 0.1652\n",
      "Epoch 183/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 93.2690 - mae: 0.1662 - val_loss: 93.3283 - val_mae: 0.1648\n",
      "Epoch 184/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 93.2584 - mae: 0.1659 - val_loss: 93.3277 - val_mae: 0.1647\n",
      "Epoch 185/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 93.2487 - mae: 0.1657 - val_loss: 93.3188 - val_mae: 0.1647\n",
      "Epoch 186/20000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 93.2384 - mae: 0.1658 - val_loss: 93.3060 - val_mae: 0.1649\n",
      "Epoch 187/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 93.2291 - mae: 0.1659 - val_loss: 93.2965 - val_mae: 0.1650\n",
      "Epoch 188/20000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 93.2212 - mae: 0.1660 - val_loss: 93.2903 - val_mae: 0.1651\n",
      "Epoch 189/20000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 93.2131 - mae: 0.1660 - val_loss: 93.2867 - val_mae: 0.1650\n",
      "Epoch 190/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.2042 - mae: 0.1659 - val_loss: 93.2850 - val_mae: 0.1648\n",
      "Epoch 191/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 93.1960 - mae: 0.1658 - val_loss: 93.2825 - val_mae: 0.1647\n",
      "Epoch 192/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 93.1890 - mae: 0.1656 - val_loss: 93.2758 - val_mae: 0.1647\n",
      "Epoch 193/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.1815 - mae: 0.1656 - val_loss: 93.2667 - val_mae: 0.1648\n",
      "Epoch 194/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.1743 - mae: 0.1657 - val_loss: 93.2601 - val_mae: 0.1648\n",
      "Epoch 195/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 93.1679 - mae: 0.1658 - val_loss: 93.2562 - val_mae: 0.1648\n",
      "Epoch 196/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 93.1612 - mae: 0.1657 - val_loss: 93.2552 - val_mae: 0.1646\n",
      "Epoch 197/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 93.1552 - mae: 0.1656 - val_loss: 93.2556 - val_mae: 0.1645\n",
      "Epoch 198/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 93.1500 - mae: 0.1655 - val_loss: 93.2528 - val_mae: 0.1645\n",
      "Epoch 199/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 93.1447 - mae: 0.1655 - val_loss: 93.2463 - val_mae: 0.1646\n",
      "Epoch 200/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 93.1387 - mae: 0.1655 - val_loss: 93.2388 - val_mae: 0.1647\n",
      "Epoch 201/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 93.1335 - mae: 0.1657 - val_loss: 93.2336 - val_mae: 0.1647\n",
      "Epoch 202/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 93.1287 - mae: 0.1657 - val_loss: 93.2316 - val_mae: 0.1646\n",
      "Epoch 203/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 93.1232 - mae: 0.1655 - val_loss: 93.2294 - val_mae: 0.1645\n",
      "Epoch 204/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 93.1185 - mae: 0.1654 - val_loss: 93.2263 - val_mae: 0.1645\n",
      "Epoch 205/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 93.1134 - mae: 0.1654 - val_loss: 93.2216 - val_mae: 0.1646\n",
      "Epoch 206/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 93.1081 - mae: 0.1655 - val_loss: 93.2183 - val_mae: 0.1648\n",
      "Epoch 207/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 93.1034 - mae: 0.1656 - val_loss: 93.2174 - val_mae: 0.1647\n",
      "Epoch 208/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 93.0992 - mae: 0.1656 - val_loss: 93.2170 - val_mae: 0.1646\n",
      "Epoch 209/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 93.0950 - mae: 0.1655 - val_loss: 93.2162 - val_mae: 0.1645\n",
      "Epoch 210/20000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 93.0912 - mae: 0.1653 - val_loss: 93.2116 - val_mae: 0.1645\n",
      "Epoch 211/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 93.0871 - mae: 0.1654 - val_loss: 93.2057 - val_mae: 0.1646\n",
      "Epoch 212/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 93.0832 - mae: 0.1654 - val_loss: 93.2015 - val_mae: 0.1647\n",
      "Epoch 213/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 93.0792 - mae: 0.1655 - val_loss: 93.2009 - val_mae: 0.1647\n",
      "Epoch 214/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 93.0752 - mae: 0.1655 - val_loss: 93.2020 - val_mae: 0.1646\n",
      "Epoch 215/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.0711 - mae: 0.1653 - val_loss: 93.2022 - val_mae: 0.1645\n",
      "Epoch 216/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 93.0675 - mae: 0.1653 - val_loss: 93.1984 - val_mae: 0.1645\n",
      "Epoch 217/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 93.0634 - mae: 0.1653 - val_loss: 93.1934 - val_mae: 0.1647\n",
      "Epoch 218/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.0596 - mae: 0.1654 - val_loss: 93.1918 - val_mae: 0.1647\n",
      "Epoch 219/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 93.0558 - mae: 0.1654 - val_loss: 93.1932 - val_mae: 0.1646\n",
      "Epoch 220/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.0517 - mae: 0.1653 - val_loss: 93.1944 - val_mae: 0.1645\n",
      "Epoch 221/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 93.0481 - mae: 0.1652 - val_loss: 93.1914 - val_mae: 0.1646\n",
      "Epoch 222/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 93.0442 - mae: 0.1653 - val_loss: 93.1863 - val_mae: 0.1647\n",
      "Epoch 223/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 93.0402 - mae: 0.1654 - val_loss: 93.1824 - val_mae: 0.1647\n",
      "Epoch 224/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 93.0362 - mae: 0.1654 - val_loss: 93.1803 - val_mae: 0.1646\n",
      "Epoch 225/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 93.0322 - mae: 0.1653 - val_loss: 93.1783 - val_mae: 0.1646\n",
      "Epoch 226/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 93.0281 - mae: 0.1652 - val_loss: 93.1754 - val_mae: 0.1646\n",
      "Epoch 227/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 93.0241 - mae: 0.1653 - val_loss: 93.1717 - val_mae: 0.1646\n",
      "Epoch 228/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 93.0201 - mae: 0.1653 - val_loss: 93.1679 - val_mae: 0.1646\n",
      "Epoch 229/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 93.0160 - mae: 0.1653 - val_loss: 93.1643 - val_mae: 0.1646\n",
      "Epoch 230/20000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 93.0122 - mae: 0.1653 - val_loss: 93.1624 - val_mae: 0.1647\n",
      "Epoch 231/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 93.0080 - mae: 0.1653 - val_loss: 93.1616 - val_mae: 0.1647\n",
      "Epoch 232/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 93.0037 - mae: 0.1653 - val_loss: 93.1614 - val_mae: 0.1646\n",
      "Epoch 233/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.9995 - mae: 0.1652 - val_loss: 93.1604 - val_mae: 0.1645\n",
      "Epoch 234/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.9946 - mae: 0.1651 - val_loss: 93.1573 - val_mae: 0.1646\n",
      "Epoch 235/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.9895 - mae: 0.1652 - val_loss: 93.1555 - val_mae: 0.1646\n",
      "Epoch 236/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.9840 - mae: 0.1652 - val_loss: 93.1551 - val_mae: 0.1646\n",
      "Epoch 237/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.9783 - mae: 0.1652 - val_loss: 93.1558 - val_mae: 0.1645\n",
      "Epoch 238/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.9723 - mae: 0.1651 - val_loss: 93.1513 - val_mae: 0.1645\n",
      "Epoch 239/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.9667 - mae: 0.1650 - val_loss: 93.1441 - val_mae: 0.1646\n",
      "Epoch 240/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 92.9620 - mae: 0.1651 - val_loss: 93.1398 - val_mae: 0.1647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.9582 - mae: 0.1653 - val_loss: 93.1367 - val_mae: 0.1647\n",
      "Epoch 242/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.9534 - mae: 0.1652 - val_loss: 93.1326 - val_mae: 0.1645\n",
      "Epoch 243/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.9486 - mae: 0.1651 - val_loss: 93.1290 - val_mae: 0.1646\n",
      "Epoch 244/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.9432 - mae: 0.1651 - val_loss: 93.1267 - val_mae: 0.1647\n",
      "Epoch 245/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.9387 - mae: 0.1652 - val_loss: 93.1241 - val_mae: 0.1647\n",
      "Epoch 246/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.9327 - mae: 0.1652 - val_loss: 93.1210 - val_mae: 0.1645\n",
      "Epoch 247/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.9278 - mae: 0.1650 - val_loss: 93.1148 - val_mae: 0.1645\n",
      "Epoch 248/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.9224 - mae: 0.1650 - val_loss: 93.1064 - val_mae: 0.1647\n",
      "Epoch 249/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.9167 - mae: 0.1651 - val_loss: 93.1026 - val_mae: 0.1646\n",
      "Epoch 250/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.9105 - mae: 0.1651 - val_loss: 93.1036 - val_mae: 0.1645\n",
      "Epoch 251/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.9044 - mae: 0.1649 - val_loss: 93.1015 - val_mae: 0.1644\n",
      "Epoch 252/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.8994 - mae: 0.1649 - val_loss: 93.0935 - val_mae: 0.1645\n",
      "Epoch 253/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.8938 - mae: 0.1650 - val_loss: 93.0858 - val_mae: 0.1645\n",
      "Epoch 254/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.8881 - mae: 0.1650 - val_loss: 93.0806 - val_mae: 0.1645\n",
      "Epoch 255/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.8830 - mae: 0.1649 - val_loss: 93.0773 - val_mae: 0.1645\n",
      "Epoch 256/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 92.8777 - mae: 0.1649 - val_loss: 93.0748 - val_mae: 0.1645\n",
      "Epoch 257/20000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 92.8719 - mae: 0.1650 - val_loss: 93.0746 - val_mae: 0.1646\n",
      "Epoch 258/20000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 92.8663 - mae: 0.1650 - val_loss: 93.0746 - val_mae: 0.1645\n",
      "Epoch 259/20000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 92.8611 - mae: 0.1649 - val_loss: 93.0757 - val_mae: 0.1644\n",
      "Epoch 260/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.8581 - mae: 0.1648 - val_loss: 93.0639 - val_mae: 0.1647\n",
      "Epoch 261/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 92.8512 - mae: 0.1650 - val_loss: 93.0600 - val_mae: 0.1647\n",
      "Epoch 262/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.8458 - mae: 0.1651 - val_loss: 93.0633 - val_mae: 0.1644\n",
      "Epoch 263/20000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 92.8409 - mae: 0.1648 - val_loss: 93.0610 - val_mae: 0.1644\n",
      "Epoch 264/20000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 92.8355 - mae: 0.1648 - val_loss: 93.0569 - val_mae: 0.1647\n",
      "Epoch 265/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.8306 - mae: 0.1650 - val_loss: 93.0594 - val_mae: 0.1646\n",
      "Epoch 266/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 92.8256 - mae: 0.1649 - val_loss: 93.0664 - val_mae: 0.1643\n",
      "Epoch 267/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 92.8210 - mae: 0.1647 - val_loss: 93.0656 - val_mae: 0.1644\n",
      "Epoch 268/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.8156 - mae: 0.1647 - val_loss: 93.0627 - val_mae: 0.1645\n",
      "Epoch 269/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.8105 - mae: 0.1648 - val_loss: 93.0617 - val_mae: 0.1645\n",
      "Epoch 270/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 92.8055 - mae: 0.1648 - val_loss: 93.0608 - val_mae: 0.1644\n",
      "Epoch 271/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 92.8007 - mae: 0.1647 - val_loss: 93.0567 - val_mae: 0.1645\n",
      "Epoch 272/20000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 92.7955 - mae: 0.1648 - val_loss: 93.0565 - val_mae: 0.1645\n",
      "Epoch 273/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.7905 - mae: 0.1648 - val_loss: 93.0587 - val_mae: 0.1644\n",
      "Epoch 274/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 92.7855 - mae: 0.1647 - val_loss: 93.0574 - val_mae: 0.1645\n",
      "Epoch 275/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.7806 - mae: 0.1647 - val_loss: 93.0556 - val_mae: 0.1644\n",
      "Epoch 276/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.7757 - mae: 0.1647 - val_loss: 93.0550 - val_mae: 0.1643\n",
      "Epoch 277/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.7709 - mae: 0.1646 - val_loss: 93.0500 - val_mae: 0.1644\n",
      "Epoch 278/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.7658 - mae: 0.1647 - val_loss: 93.0479 - val_mae: 0.1645\n",
      "Epoch 279/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.7609 - mae: 0.1647 - val_loss: 93.0538 - val_mae: 0.1643\n",
      "Epoch 280/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.7564 - mae: 0.1646 - val_loss: 93.0489 - val_mae: 0.1646\n",
      "Epoch 281/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.7510 - mae: 0.1647 - val_loss: 93.0483 - val_mae: 0.1644\n",
      "Epoch 282/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 92.7464 - mae: 0.1646 - val_loss: 93.0454 - val_mae: 0.1643\n",
      "Epoch 283/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.7420 - mae: 0.1645 - val_loss: 93.0406 - val_mae: 0.1645\n",
      "Epoch 284/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.7365 - mae: 0.1647 - val_loss: 93.0445 - val_mae: 0.1643\n",
      "Epoch 285/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.7317 - mae: 0.1645 - val_loss: 93.0429 - val_mae: 0.1644\n",
      "Epoch 286/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 92.7264 - mae: 0.1645 - val_loss: 93.0409 - val_mae: 0.1645\n",
      "Epoch 287/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 92.7215 - mae: 0.1646 - val_loss: 93.0392 - val_mae: 0.1643\n",
      "Epoch 288/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.7162 - mae: 0.1645 - val_loss: 93.0298 - val_mae: 0.1645\n",
      "Epoch 289/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 92.7106 - mae: 0.1646 - val_loss: 93.0241 - val_mae: 0.1644\n",
      "Epoch 290/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.7057 - mae: 0.1645 - val_loss: 93.0194 - val_mae: 0.1643\n",
      "Epoch 291/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.7007 - mae: 0.1645 - val_loss: 93.0128 - val_mae: 0.1645\n",
      "Epoch 292/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.6961 - mae: 0.1646 - val_loss: 93.0127 - val_mae: 0.1643\n",
      "Epoch 293/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.6911 - mae: 0.1644 - val_loss: 93.0113 - val_mae: 0.1645\n",
      "Epoch 294/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 92.6853 - mae: 0.1646 - val_loss: 93.0150 - val_mae: 0.1645\n",
      "Epoch 295/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 92.6795 - mae: 0.1646 - val_loss: 93.0273 - val_mae: 0.1643\n",
      "Epoch 296/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.6752 - mae: 0.1643 - val_loss: 93.0210 - val_mae: 0.1648\n",
      "Epoch 297/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.6710 - mae: 0.1648 - val_loss: 93.0282 - val_mae: 0.1641\n",
      "Epoch 298/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 92.6640 - mae: 0.1642 - val_loss: 93.0164 - val_mae: 0.1645\n",
      "Epoch 299/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.6575 - mae: 0.1645 - val_loss: 93.0124 - val_mae: 0.1646\n",
      "Epoch 300/20000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 92.6528 - mae: 0.1646 - val_loss: 93.0212 - val_mae: 0.1642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.6471 - mae: 0.1642 - val_loss: 93.0138 - val_mae: 0.1646\n",
      "Epoch 302/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.6418 - mae: 0.1646 - val_loss: 93.0199 - val_mae: 0.1642\n",
      "Epoch 303/20000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 92.6352 - mae: 0.1642 - val_loss: 93.0158 - val_mae: 0.1643\n",
      "Epoch 304/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 92.6292 - mae: 0.1642 - val_loss: 93.0061 - val_mae: 0.1645\n",
      "Epoch 305/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.6234 - mae: 0.1644 - val_loss: 93.0057 - val_mae: 0.1643\n",
      "Epoch 306/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.6178 - mae: 0.1642 - val_loss: 92.9989 - val_mae: 0.1646\n",
      "Epoch 307/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.6121 - mae: 0.1645 - val_loss: 93.0073 - val_mae: 0.1641\n",
      "Epoch 308/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.6063 - mae: 0.1641 - val_loss: 93.0003 - val_mae: 0.1645\n",
      "Epoch 309/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 92.5996 - mae: 0.1644 - val_loss: 93.0059 - val_mae: 0.1642\n",
      "Epoch 310/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.5933 - mae: 0.1641 - val_loss: 92.9981 - val_mae: 0.1646\n",
      "Epoch 311/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 92.5880 - mae: 0.1645 - val_loss: 93.0111 - val_mae: 0.1640\n",
      "Epoch 312/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.5825 - mae: 0.1639 - val_loss: 92.9992 - val_mae: 0.1647\n",
      "Epoch 313/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 92.5771 - mae: 0.1646 - val_loss: 93.0146 - val_mae: 0.1639\n",
      "Epoch 314/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.5716 - mae: 0.1637 - val_loss: 92.9972 - val_mae: 0.1648\n",
      "Epoch 315/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.5639 - mae: 0.1646 - val_loss: 93.0137 - val_mae: 0.1639\n",
      "Epoch 316/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.5572 - mae: 0.1638 - val_loss: 93.0047 - val_mae: 0.1645\n",
      "Epoch 317/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.5489 - mae: 0.1643 - val_loss: 93.0097 - val_mae: 0.1644\n",
      "Epoch 318/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.5420 - mae: 0.1642 - val_loss: 93.0199 - val_mae: 0.1641\n",
      "Epoch 319/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.5367 - mae: 0.1639 - val_loss: 93.0111 - val_mae: 0.1646\n",
      "Epoch 320/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 92.5310 - mae: 0.1644 - val_loss: 93.0285 - val_mae: 0.1638\n",
      "Epoch 321/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.5270 - mae: 0.1636 - val_loss: 93.0064 - val_mae: 0.1649\n",
      "Epoch 322/20000\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 92.5223 - mae: 0.1646 - val_loss: 93.0359 - val_mae: 0.1636\n",
      "Epoch 323/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.5174 - mae: 0.1634 - val_loss: 93.0088 - val_mae: 0.1646\n",
      "Epoch 324/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.5062 - mae: 0.1644 - val_loss: 93.0175 - val_mae: 0.1643\n",
      "Epoch 325/20000\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 92.4972 - mae: 0.1640 - val_loss: 93.0361 - val_mae: 0.1638\n",
      "Epoch 326/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.4934 - mae: 0.1636 - val_loss: 93.0178 - val_mae: 0.1648\n",
      "Epoch 327/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.4894 - mae: 0.1645 - val_loss: 93.0494 - val_mae: 0.1637\n",
      "Epoch 328/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.4809 - mae: 0.1635 - val_loss: 93.0346 - val_mae: 0.1643\n",
      "Epoch 329/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.4708 - mae: 0.1641 - val_loss: 93.0368 - val_mae: 0.1644\n",
      "Epoch 330/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.4640 - mae: 0.1641 - val_loss: 93.0612 - val_mae: 0.1638\n",
      "Epoch 331/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 92.4597 - mae: 0.1635 - val_loss: 93.0365 - val_mae: 0.1647\n",
      "Epoch 332/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.4532 - mae: 0.1643 - val_loss: 93.0573 - val_mae: 0.1639\n",
      "Epoch 333/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.4438 - mae: 0.1636 - val_loss: 93.0488 - val_mae: 0.1642\n",
      "Epoch 334/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.4354 - mae: 0.1639 - val_loss: 93.0500 - val_mae: 0.1643\n",
      "Epoch 335/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 92.4279 - mae: 0.1639 - val_loss: 93.0629 - val_mae: 0.1639\n",
      "Epoch 336/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.4210 - mae: 0.1636 - val_loss: 93.0509 - val_mae: 0.1644\n",
      "Epoch 337/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.4151 - mae: 0.1641 - val_loss: 93.0819 - val_mae: 0.1635\n",
      "Epoch 338/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 92.4114 - mae: 0.1632 - val_loss: 93.0471 - val_mae: 0.1649\n",
      "Epoch 339/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.4085 - mae: 0.1645 - val_loss: 93.0997 - val_mae: 0.1633\n",
      "Epoch 340/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.3991 - mae: 0.1630 - val_loss: 93.0606 - val_mae: 0.1645\n",
      "Epoch 341/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.3887 - mae: 0.1642 - val_loss: 93.0900 - val_mae: 0.1637\n",
      "Epoch 342/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 92.3769 - mae: 0.1633 - val_loss: 93.0805 - val_mae: 0.1641\n",
      "Epoch 343/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.3679 - mae: 0.1637 - val_loss: 93.0766 - val_mae: 0.1643\n",
      "Epoch 344/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.3612 - mae: 0.1639 - val_loss: 93.1205 - val_mae: 0.1633\n",
      "Epoch 345/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.3592 - mae: 0.1629 - val_loss: 93.0739 - val_mae: 0.1649\n",
      "Epoch 346/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.3589 - mae: 0.1645 - val_loss: 93.1348 - val_mae: 0.1633\n",
      "Epoch 347/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 92.3452 - mae: 0.1629 - val_loss: 93.1020 - val_mae: 0.1643\n",
      "Epoch 348/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 92.3304 - mae: 0.1638 - val_loss: 93.1185 - val_mae: 0.1640\n",
      "Epoch 349/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.3205 - mae: 0.1636 - val_loss: 93.1524 - val_mae: 0.1633\n",
      "Epoch 350/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.3172 - mae: 0.1629 - val_loss: 93.1117 - val_mae: 0.1645\n",
      "Epoch 351/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 92.3122 - mae: 0.1640 - val_loss: 93.1600 - val_mae: 0.1633\n",
      "Epoch 352/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.3025 - mae: 0.1628 - val_loss: 93.1095 - val_mae: 0.1645\n",
      "Epoch 353/20000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 92.2922 - mae: 0.1640 - val_loss: 93.1444 - val_mae: 0.1635\n",
      "Epoch 354/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.2801 - mae: 0.1631 - val_loss: 93.1319 - val_mae: 0.1639\n",
      "Epoch 355/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.2699 - mae: 0.1634 - val_loss: 93.1413 - val_mae: 0.1638\n",
      "Epoch 356/20000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 92.2598 - mae: 0.1634 - val_loss: 93.1592 - val_mae: 0.1637\n",
      "Epoch 357/20000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 92.2519 - mae: 0.1632 - val_loss: 93.1508 - val_mae: 0.1641\n",
      "Epoch 358/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.2437 - mae: 0.1636 - val_loss: 93.2039 - val_mae: 0.1631\n",
      "Epoch 359/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.2378 - mae: 0.1626 - val_loss: 93.1472 - val_mae: 0.1645\n",
      "Epoch 360/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.2364 - mae: 0.1640 - val_loss: 93.2473 - val_mae: 0.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.2373 - mae: 0.1621 - val_loss: 93.1362 - val_mae: 0.1652\n",
      "Epoch 362/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 92.2417 - mae: 0.1647 - val_loss: 93.2432 - val_mae: 0.1626\n",
      "Epoch 363/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 92.2158 - mae: 0.1621 - val_loss: 93.1713 - val_mae: 0.1640\n",
      "Epoch 364/20000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 92.1910 - mae: 0.1634 - val_loss: 93.1785 - val_mae: 0.1639\n",
      "Epoch 365/20000\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 92.1831 - mae: 0.1634 - val_loss: 93.2577 - val_mae: 0.1626\n",
      "Epoch 366/20000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 92.1846 - mae: 0.1621 - val_loss: 93.1708 - val_mae: 0.1647\n",
      "Epoch 367/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.1831 - mae: 0.1642 - val_loss: 93.2601 - val_mae: 0.1629\n",
      "Epoch 368/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.1629 - mae: 0.1623 - val_loss: 93.2187 - val_mae: 0.1635\n",
      "Epoch 369/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.1440 - mae: 0.1630 - val_loss: 93.1931 - val_mae: 0.1640\n",
      "Epoch 370/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 92.1413 - mae: 0.1635 - val_loss: 93.2871 - val_mae: 0.1624\n",
      "Epoch 371/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 92.1403 - mae: 0.1619 - val_loss: 93.1739 - val_mae: 0.1646\n",
      "Epoch 372/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 92.1379 - mae: 0.1640 - val_loss: 93.2665 - val_mae: 0.1628\n",
      "Epoch 373/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.1115 - mae: 0.1622 - val_loss: 93.2448 - val_mae: 0.1631\n",
      "Epoch 374/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.0960 - mae: 0.1626 - val_loss: 93.1947 - val_mae: 0.1641\n",
      "Epoch 375/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.0977 - mae: 0.1636 - val_loss: 93.3242 - val_mae: 0.1620\n",
      "Epoch 376/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 92.0998 - mae: 0.1615 - val_loss: 93.1776 - val_mae: 0.1648\n",
      "Epoch 377/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.1015 - mae: 0.1642 - val_loss: 93.2959 - val_mae: 0.1625\n",
      "Epoch 378/20000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 92.0659 - mae: 0.1619 - val_loss: 93.2576 - val_mae: 0.1631\n",
      "Epoch 379/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 92.0450 - mae: 0.1625 - val_loss: 93.2139 - val_mae: 0.1640\n",
      "Epoch 380/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 92.0462 - mae: 0.1634 - val_loss: 93.3393 - val_mae: 0.1619\n",
      "Epoch 381/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 92.0469 - mae: 0.1614 - val_loss: 93.1910 - val_mae: 0.1645\n",
      "Epoch 382/20000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 92.0428 - mae: 0.1639 - val_loss: 93.3026 - val_mae: 0.1624\n",
      "Epoch 383/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 92.0134 - mae: 0.1618 - val_loss: 93.2545 - val_mae: 0.1632\n",
      "Epoch 384/20000\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 91.9927 - mae: 0.1626 - val_loss: 93.2379 - val_mae: 0.1636\n",
      "Epoch 385/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 91.9875 - mae: 0.1630 - val_loss: 93.3469 - val_mae: 0.1621\n",
      "Epoch 386/20000\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 91.9838 - mae: 0.1615 - val_loss: 93.2205 - val_mae: 0.1642\n",
      "Epoch 387/20000\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 91.9797 - mae: 0.1635 - val_loss: 93.3375 - val_mae: 0.1621\n",
      "Epoch 388/20000\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 91.9567 - mae: 0.1615 - val_loss: 93.2591 - val_mae: 0.1633\n",
      "Epoch 389/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.9384 - mae: 0.1627 - val_loss: 93.2782 - val_mae: 0.1630\n",
      "Epoch 390/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 91.9243 - mae: 0.1624 - val_loss: 93.3336 - val_mae: 0.1623\n",
      "Epoch 391/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 91.9163 - mae: 0.1617 - val_loss: 93.2466 - val_mae: 0.1637\n",
      "Epoch 392/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.9121 - mae: 0.1631 - val_loss: 93.3775 - val_mae: 0.1619\n",
      "Epoch 393/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.8977 - mae: 0.1613 - val_loss: 93.2573 - val_mae: 0.1638\n",
      "Epoch 394/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.8911 - mae: 0.1631 - val_loss: 93.4072 - val_mae: 0.1617\n",
      "Epoch 395/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.8766 - mae: 0.1610 - val_loss: 93.2592 - val_mae: 0.1639\n",
      "Epoch 396/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.8738 - mae: 0.1633 - val_loss: 93.4479 - val_mae: 0.1615\n",
      "Epoch 397/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.8576 - mae: 0.1608 - val_loss: 93.2649 - val_mae: 0.1642\n",
      "Epoch 398/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.8657 - mae: 0.1636 - val_loss: 93.5382 - val_mae: 0.1608\n",
      "Epoch 399/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.8577 - mae: 0.1601 - val_loss: 93.2552 - val_mae: 0.1650\n",
      "Epoch 400/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 91.8969 - mae: 0.1644 - val_loss: 93.5038 - val_mae: 0.1612\n",
      "Epoch 401/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.8128 - mae: 0.1605 - val_loss: 93.3874 - val_mae: 0.1624\n",
      "Epoch 402/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.7760 - mae: 0.1617 - val_loss: 93.3120 - val_mae: 0.1636\n",
      "Epoch 403/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 91.7808 - mae: 0.1629 - val_loss: 93.5423 - val_mae: 0.1610\n",
      "Epoch 404/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 91.7811 - mae: 0.1603 - val_loss: 93.2904 - val_mae: 0.1644\n",
      "Epoch 405/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 91.8030 - mae: 0.1637 - val_loss: 93.5369 - val_mae: 0.1610\n",
      "Epoch 406/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 91.7485 - mae: 0.1603 - val_loss: 93.3869 - val_mae: 0.1626\n",
      "Epoch 407/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.7134 - mae: 0.1619 - val_loss: 93.3676 - val_mae: 0.1630\n",
      "Epoch 408/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 91.7053 - mae: 0.1622 - val_loss: 93.5649 - val_mae: 0.1611\n",
      "Epoch 409/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.7105 - mae: 0.1603 - val_loss: 93.3177 - val_mae: 0.1642\n",
      "Epoch 410/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.7329 - mae: 0.1635 - val_loss: 93.6431 - val_mae: 0.1604\n",
      "Epoch 411/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.7005 - mae: 0.1597 - val_loss: 93.3433 - val_mae: 0.1635\n",
      "Epoch 412/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.6756 - mae: 0.1628 - val_loss: 93.4865 - val_mae: 0.1617\n",
      "Epoch 413/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 91.6375 - mae: 0.1610 - val_loss: 93.4734 - val_mae: 0.1619\n",
      "Epoch 414/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.6220 - mae: 0.1611 - val_loss: 93.3684 - val_mae: 0.1631\n",
      "Epoch 415/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.6207 - mae: 0.1623 - val_loss: 93.6230 - val_mae: 0.1606\n",
      "Epoch 416/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 91.6170 - mae: 0.1599 - val_loss: 93.3422 - val_mae: 0.1639\n",
      "Epoch 417/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.6325 - mae: 0.1631 - val_loss: 93.6901 - val_mae: 0.1603\n",
      "Epoch 418/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.6044 - mae: 0.1595 - val_loss: 93.3366 - val_mae: 0.1640\n",
      "Epoch 419/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 91.6047 - mae: 0.1632 - val_loss: 93.6404 - val_mae: 0.1606\n",
      "Epoch 420/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.5574 - mae: 0.1598 - val_loss: 93.4391 - val_mae: 0.1625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/20000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 91.5285 - mae: 0.1617 - val_loss: 93.5125 - val_mae: 0.1618\n",
      "Epoch 422/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 91.5069 - mae: 0.1610 - val_loss: 93.6163 - val_mae: 0.1610\n",
      "Epoch 423/20000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 91.4999 - mae: 0.1602 - val_loss: 93.3863 - val_mae: 0.1635\n",
      "Epoch 424/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.5130 - mae: 0.1626 - val_loss: 93.7961 - val_mae: 0.1598\n",
      "Epoch 425/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.5175 - mae: 0.1589 - val_loss: 93.3336 - val_mae: 0.1648\n",
      "Epoch 426/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 91.5808 - mae: 0.1639 - val_loss: 93.9134 - val_mae: 0.1590\n",
      "Epoch 427/20000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 91.5171 - mae: 0.1582 - val_loss: 93.3843 - val_mae: 0.1639\n",
      "Epoch 428/20000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 91.4855 - mae: 0.1630 - val_loss: 93.6619 - val_mae: 0.1610\n",
      "Epoch 429/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 91.4103 - mae: 0.1600 - val_loss: 93.6789 - val_mae: 0.1609\n",
      "Epoch 430/20000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 91.3970 - mae: 0.1600 - val_loss: 93.3921 - val_mae: 0.1638\n",
      "Epoch 431/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 91.4391 - mae: 0.1629 - val_loss: 93.9654 - val_mae: 0.1589\n",
      "Epoch 432/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.4360 - mae: 0.1580 - val_loss: 93.3662 - val_mae: 0.1645\n",
      "Epoch 433/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.4753 - mae: 0.1636 - val_loss: 93.8656 - val_mae: 0.1595\n",
      "Epoch 434/20000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 91.3662 - mae: 0.1585 - val_loss: 93.4923 - val_mae: 0.1624\n",
      "Epoch 435/20000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 91.3220 - mae: 0.1614 - val_loss: 93.6158 - val_mae: 0.1613\n",
      "Epoch 436/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.2920 - mae: 0.1603 - val_loss: 93.7337 - val_mae: 0.1604\n",
      "Epoch 437/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.2838 - mae: 0.1593 - val_loss: 93.4419 - val_mae: 0.1630\n",
      "Epoch 438/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 91.3057 - mae: 0.1620 - val_loss: 93.9705 - val_mae: 0.1588\n",
      "Epoch 439/20000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 91.3065 - mae: 0.1578 - val_loss: 93.3635 - val_mae: 0.1647\n",
      "Epoch 440/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.3884 - mae: 0.1636 - val_loss: 94.1236 - val_mae: 0.1582\n",
      "Epoch 441/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 91.3290 - mae: 0.1571 - val_loss: 93.3618 - val_mae: 0.1649\n",
      "Epoch 442/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 91.3847 - mae: 0.1639 - val_loss: 93.9320 - val_mae: 0.1591\n",
      "Epoch 443/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.2207 - mae: 0.1580 - val_loss: 93.6103 - val_mae: 0.1612\n",
      "Epoch 444/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 91.1646 - mae: 0.1601 - val_loss: 93.5463 - val_mae: 0.1617\n",
      "Epoch 445/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.1545 - mae: 0.1606 - val_loss: 93.9456 - val_mae: 0.1590\n",
      "Epoch 446/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 91.1791 - mae: 0.1578 - val_loss: 93.3607 - val_mae: 0.1646\n",
      "Epoch 447/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.2891 - mae: 0.1635 - val_loss: 94.1683 - val_mae: 0.1578\n",
      "Epoch 448/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 91.2071 - mae: 0.1566 - val_loss: 93.3906 - val_mae: 0.1641\n",
      "Epoch 449/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 91.2220 - mae: 0.1629 - val_loss: 93.9217 - val_mae: 0.1591\n",
      "Epoch 450/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.0933 - mae: 0.1579 - val_loss: 93.6595 - val_mae: 0.1609\n",
      "Epoch 451/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 91.0475 - mae: 0.1596 - val_loss: 93.5549 - val_mae: 0.1617\n",
      "Epoch 452/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 91.0418 - mae: 0.1604 - val_loss: 93.9588 - val_mae: 0.1589\n",
      "Epoch 453/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.0479 - mae: 0.1575 - val_loss: 93.3992 - val_mae: 0.1639\n",
      "Epoch 454/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.1294 - mae: 0.1626 - val_loss: 94.2761 - val_mae: 0.1572\n",
      "Epoch 455/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.1213 - mae: 0.1558 - val_loss: 93.3484 - val_mae: 0.1660\n",
      "Epoch 456/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.3448 - mae: 0.1647 - val_loss: 94.0855 - val_mae: 0.1582\n",
      "Epoch 457/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 91.0060 - mae: 0.1568 - val_loss: 93.7536 - val_mae: 0.1603\n",
      "Epoch 458/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 90.9240 - mae: 0.1589 - val_loss: 93.5306 - val_mae: 0.1623\n",
      "Epoch 459/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.9538 - mae: 0.1609 - val_loss: 94.2713 - val_mae: 0.1574\n",
      "Epoch 460/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 90.9958 - mae: 0.1559 - val_loss: 93.3874 - val_mae: 0.1653\n",
      "Epoch 461/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 91.1837 - mae: 0.1638 - val_loss: 94.2541 - val_mae: 0.1575\n",
      "Epoch 462/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 90.9585 - mae: 0.1559 - val_loss: 93.5467 - val_mae: 0.1621\n",
      "Epoch 463/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 90.8789 - mae: 0.1605 - val_loss: 93.7834 - val_mae: 0.1600\n",
      "Epoch 464/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 90.8238 - mae: 0.1584 - val_loss: 93.9249 - val_mae: 0.1592\n",
      "Epoch 465/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.8248 - mae: 0.1575 - val_loss: 93.4459 - val_mae: 0.1633\n",
      "Epoch 466/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 90.9065 - mae: 0.1617 - val_loss: 94.4069 - val_mae: 0.1566\n",
      "Epoch 467/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 90.9399 - mae: 0.1548 - val_loss: 93.3914 - val_mae: 0.1659\n",
      "Epoch 468/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 91.1833 - mae: 0.1643 - val_loss: 94.1692 - val_mae: 0.1578\n",
      "Epoch 469/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.8122 - mae: 0.1560 - val_loss: 93.9154 - val_mae: 0.1592\n",
      "Epoch 470/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 90.7377 - mae: 0.1574 - val_loss: 93.4324 - val_mae: 0.1637\n",
      "Epoch 471/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 90.8760 - mae: 0.1620 - val_loss: 94.5342 - val_mae: 0.1560\n",
      "Epoch 472/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 90.9189 - mae: 0.1541 - val_loss: 93.4056 - val_mae: 0.1661\n",
      "Epoch 473/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 91.1518 - mae: 0.1644 - val_loss: 93.9352 - val_mae: 0.1590\n",
      "Epoch 474/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 90.6825 - mae: 0.1572 - val_loss: 94.9034 - val_mae: 0.1544\n",
      "Epoch 475/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 91.0240 - mae: 0.1524 - val_loss: 93.7262 - val_mae: 0.1701\n",
      "Epoch 476/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.9615 - mae: 0.1686 - val_loss: 93.4508 - val_mae: 0.1663\n",
      "Epoch 477/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.1471 - mae: 0.1646 - val_loss: 99.4221 - val_mae: 0.1426\n",
      "Epoch 478/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 93.8340 - mae: 0.1407 - val_loss: 94.9770 - val_mae: 0.1754\n",
      "Epoch 479/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 93.9324 - mae: 0.1742 - val_loss: 96.3309 - val_mae: 0.1787\n",
      "Epoch 480/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 95.8920 - mae: 0.1779 - val_loss: 96.4669 - val_mae: 0.1789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 96.1239 - mae: 0.1782 - val_loss: 96.0978 - val_mae: 0.1781\n",
      "Epoch 482/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 95.6918 - mae: 0.1774 - val_loss: 95.3523 - val_mae: 0.1761\n",
      "Epoch 483/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 94.7848 - mae: 0.1754 - val_loss: 94.4314 - val_mae: 0.1719\n",
      "Epoch 484/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 93.5587 - mae: 0.1712 - val_loss: 94.3015 - val_mae: 0.1637\n",
      "Epoch 485/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.9021 - mae: 0.1630 - val_loss: 96.3701 - val_mae: 0.1530\n",
      "Epoch 486/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 94.3938 - mae: 0.1522 - val_loss: 95.5104 - val_mae: 0.1549\n",
      "Epoch 487/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 93.7378 - mae: 0.1541 - val_loss: 93.9345 - val_mae: 0.1622\n",
      "Epoch 488/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 92.6475 - mae: 0.1615 - val_loss: 93.5926 - val_mae: 0.1677\n",
      "Epoch 489/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 92.6571 - mae: 0.1671 - val_loss: 93.7716 - val_mae: 0.1708\n",
      "Epoch 490/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 93.0348 - mae: 0.1702 - val_loss: 93.8588 - val_mae: 0.1718\n",
      "Epoch 491/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 93.2113 - mae: 0.1712 - val_loss: 93.6659 - val_mae: 0.1712\n",
      "Epoch 492/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 93.0408 - mae: 0.1705 - val_loss: 93.3032 - val_mae: 0.1690\n",
      "Epoch 493/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.6393 - mae: 0.1683 - val_loss: 93.0986 - val_mae: 0.1652\n",
      "Epoch 494/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.3381 - mae: 0.1645 - val_loss: 93.3667 - val_mae: 0.1607\n",
      "Epoch 495/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.4607 - mae: 0.1600 - val_loss: 93.8195 - val_mae: 0.1576\n",
      "Epoch 496/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.7914 - mae: 0.1569 - val_loss: 93.7293 - val_mae: 0.1581\n",
      "Epoch 497/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 92.7029 - mae: 0.1574 - val_loss: 93.2882 - val_mae: 0.1614\n",
      "Epoch 498/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 92.3578 - mae: 0.1607 - val_loss: 93.0883 - val_mae: 0.1651\n",
      "Epoch 499/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.2623 - mae: 0.1643 - val_loss: 93.1627 - val_mae: 0.1676\n",
      "Epoch 500/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 92.4013 - mae: 0.1668 - val_loss: 93.2522 - val_mae: 0.1685\n",
      "Epoch 501/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 92.4981 - mae: 0.1678 - val_loss: 93.2254 - val_mae: 0.1681\n",
      "Epoch 502/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 92.4232 - mae: 0.1674 - val_loss: 93.1427 - val_mae: 0.1664\n",
      "Epoch 503/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 92.2299 - mae: 0.1656 - val_loss: 93.1793 - val_mae: 0.1637\n",
      "Epoch 504/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.0947 - mae: 0.1629 - val_loss: 93.4090 - val_mae: 0.1608\n",
      "Epoch 505/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 92.1398 - mae: 0.1600 - val_loss: 93.5989 - val_mae: 0.1593\n",
      "Epoch 506/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 92.2089 - mae: 0.1584 - val_loss: 93.5285 - val_mae: 0.1598\n",
      "Epoch 507/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 92.1156 - mae: 0.1590 - val_loss: 93.3266 - val_mae: 0.1619\n",
      "Epoch 508/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.9797 - mae: 0.1611 - val_loss: 93.2138 - val_mae: 0.1641\n",
      "Epoch 509/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 91.9593 - mae: 0.1632 - val_loss: 93.2092 - val_mae: 0.1654\n",
      "Epoch 510/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.0082 - mae: 0.1646 - val_loss: 93.2228 - val_mae: 0.1658\n",
      "Epoch 511/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.0165 - mae: 0.1650 - val_loss: 93.2205 - val_mae: 0.1649\n",
      "Epoch 512/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 91.9467 - mae: 0.1641 - val_loss: 93.2638 - val_mae: 0.1632\n",
      "Epoch 513/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.8697 - mae: 0.1624 - val_loss: 93.3933 - val_mae: 0.1613\n",
      "Epoch 514/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 91.8574 - mae: 0.1604 - val_loss: 93.5265 - val_mae: 0.1600\n",
      "Epoch 515/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.8817 - mae: 0.1590 - val_loss: 93.5032 - val_mae: 0.1601\n",
      "Epoch 516/20000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 91.8416 - mae: 0.1591 - val_loss: 93.3462 - val_mae: 0.1614\n",
      "Epoch 517/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 91.7573 - mae: 0.1604 - val_loss: 93.2133 - val_mae: 0.1630\n",
      "Epoch 518/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.7208 - mae: 0.1621 - val_loss: 93.1598 - val_mae: 0.1641\n",
      "Epoch 519/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.7217 - mae: 0.1631 - val_loss: 93.1539 - val_mae: 0.1642\n",
      "Epoch 520/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.6976 - mae: 0.1632 - val_loss: 93.2032 - val_mae: 0.1632\n",
      "Epoch 521/20000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 91.6363 - mae: 0.1621 - val_loss: 93.3352 - val_mae: 0.1616\n",
      "Epoch 522/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 91.5994 - mae: 0.1604 - val_loss: 93.4816 - val_mae: 0.1603\n",
      "Epoch 523/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 91.6014 - mae: 0.1591 - val_loss: 93.4753 - val_mae: 0.1605\n",
      "Epoch 524/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.5553 - mae: 0.1592 - val_loss: 93.3412 - val_mae: 0.1617\n",
      "Epoch 525/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.4867 - mae: 0.1605 - val_loss: 93.2439 - val_mae: 0.1629\n",
      "Epoch 526/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.4592 - mae: 0.1616 - val_loss: 93.2222 - val_mae: 0.1631\n",
      "Epoch 527/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.4224 - mae: 0.1618 - val_loss: 93.2906 - val_mae: 0.1621\n",
      "Epoch 528/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.3490 - mae: 0.1608 - val_loss: 93.4556 - val_mae: 0.1605\n",
      "Epoch 529/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.2996 - mae: 0.1591 - val_loss: 93.5694 - val_mae: 0.1596\n",
      "Epoch 530/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 91.2672 - mae: 0.1580 - val_loss: 93.4650 - val_mae: 0.1602\n",
      "Epoch 531/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.1920 - mae: 0.1586 - val_loss: 93.2960 - val_mae: 0.1615\n",
      "Epoch 532/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 91.1339 - mae: 0.1599 - val_loss: 93.2507 - val_mae: 0.1619\n",
      "Epoch 533/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.0913 - mae: 0.1603 - val_loss: 93.3439 - val_mae: 0.1611\n",
      "Epoch 534/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 91.0262 - mae: 0.1594 - val_loss: 93.5419 - val_mae: 0.1596\n",
      "Epoch 535/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 90.9847 - mae: 0.1578 - val_loss: 93.5913 - val_mae: 0.1593\n",
      "Epoch 536/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 90.9474 - mae: 0.1575 - val_loss: 93.4275 - val_mae: 0.1606\n",
      "Epoch 537/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 90.8908 - mae: 0.1588 - val_loss: 93.3417 - val_mae: 0.1615\n",
      "Epoch 538/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 90.8667 - mae: 0.1597 - val_loss: 93.4359 - val_mae: 0.1607\n",
      "Epoch 539/20000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 90.8160 - mae: 0.1588 - val_loss: 93.6596 - val_mae: 0.1589\n",
      "Epoch 540/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 90.7900 - mae: 0.1570 - val_loss: 93.6312 - val_mae: 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 90.7528 - mae: 0.1571 - val_loss: 93.4381 - val_mae: 0.1606\n",
      "Epoch 542/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 90.7259 - mae: 0.1586 - val_loss: 93.4321 - val_mae: 0.1606\n",
      "Epoch 543/20000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 90.6994 - mae: 0.1585 - val_loss: 93.6044 - val_mae: 0.1589\n",
      "Epoch 544/20000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 90.6723 - mae: 0.1568 - val_loss: 93.5843 - val_mae: 0.1589\n",
      "Epoch 545/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 90.6500 - mae: 0.1567 - val_loss: 93.3978 - val_mae: 0.1604\n",
      "Epoch 546/20000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 90.6299 - mae: 0.1583 - val_loss: 93.4076 - val_mae: 0.1603\n",
      "Epoch 547/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 90.6078 - mae: 0.1581 - val_loss: 93.5872 - val_mae: 0.1588\n",
      "Epoch 548/20000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 90.5863 - mae: 0.1565 - val_loss: 93.5474 - val_mae: 0.1592\n",
      "Epoch 549/20000\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 90.5546 - mae: 0.1569 - val_loss: 93.4547 - val_mae: 0.1604\n",
      "Epoch 550/20000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 90.5347 - mae: 0.1580 - val_loss: 93.5465 - val_mae: 0.1598\n",
      "Epoch 551/20000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 90.5079 - mae: 0.1573 - val_loss: 93.6707 - val_mae: 0.1589\n",
      "Epoch 552/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 90.4982 - mae: 0.1563 - val_loss: 93.5565 - val_mae: 0.1600\n",
      "Epoch 553/20000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 90.4745 - mae: 0.1574 - val_loss: 93.5463 - val_mae: 0.1601\n",
      "Epoch 554/20000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 90.4573 - mae: 0.1575 - val_loss: 93.6774 - val_mae: 0.1590\n",
      "Epoch 555/20000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 90.4399 - mae: 0.1563 - val_loss: 93.5777 - val_mae: 0.1599\n",
      "Epoch 556/20000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 90.4155 - mae: 0.1572 - val_loss: 93.5687 - val_mae: 0.1600\n",
      "Epoch 557/20000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 90.3997 - mae: 0.1573 - val_loss: 93.6864 - val_mae: 0.1591\n",
      "Epoch 558/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 90.3843 - mae: 0.1564 - val_loss: 93.6663 - val_mae: 0.1595\n",
      "Epoch 559/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 90.3660 - mae: 0.1567 - val_loss: 93.6306 - val_mae: 0.1601\n",
      "Epoch 560/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.3542 - mae: 0.1573 - val_loss: 93.7661 - val_mae: 0.1592\n",
      "Epoch 561/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 90.3392 - mae: 0.1564 - val_loss: 93.7717 - val_mae: 0.1595\n",
      "Epoch 562/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 90.3235 - mae: 0.1566 - val_loss: 93.7221 - val_mae: 0.1602\n",
      "Epoch 563/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 90.3140 - mae: 0.1573 - val_loss: 93.8948 - val_mae: 0.1590\n",
      "Epoch 564/20000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 90.3011 - mae: 0.1561 - val_loss: 93.8406 - val_mae: 0.1596\n",
      "Epoch 565/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 90.2841 - mae: 0.1567 - val_loss: 93.8229 - val_mae: 0.1599\n",
      "Epoch 566/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 90.2727 - mae: 0.1570 - val_loss: 93.9497 - val_mae: 0.1589\n",
      "Epoch 567/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 90.2637 - mae: 0.1560 - val_loss: 93.8010 - val_mae: 0.1602\n",
      "Epoch 568/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 90.2529 - mae: 0.1572 - val_loss: 93.9003 - val_mae: 0.1593\n",
      "Epoch 569/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 90.2383 - mae: 0.1563 - val_loss: 93.8923 - val_mae: 0.1594\n",
      "Epoch 570/20000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 90.2271 - mae: 0.1564 - val_loss: 93.8209 - val_mae: 0.1601\n",
      "Epoch 571/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 90.2201 - mae: 0.1571 - val_loss: 93.9859 - val_mae: 0.1589\n",
      "Epoch 572/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 90.2100 - mae: 0.1558 - val_loss: 93.8547 - val_mae: 0.1602\n",
      "Epoch 573/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 90.1995 - mae: 0.1571 - val_loss: 93.9918 - val_mae: 0.1592\n",
      "Epoch 574/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 90.1858 - mae: 0.1561 - val_loss: 93.9797 - val_mae: 0.1594\n",
      "Epoch 575/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 90.1754 - mae: 0.1563 - val_loss: 93.9310 - val_mae: 0.1598\n",
      "Epoch 576/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 90.1679 - mae: 0.1567 - val_loss: 94.0582 - val_mae: 0.1588\n",
      "Epoch 577/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 90.1601 - mae: 0.1557 - val_loss: 93.9211 - val_mae: 0.1599\n",
      "Epoch 578/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.1501 - mae: 0.1568 - val_loss: 94.0197 - val_mae: 0.1591\n",
      "Epoch 579/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.1378 - mae: 0.1560 - val_loss: 94.0054 - val_mae: 0.1592\n",
      "Epoch 580/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 90.1277 - mae: 0.1561 - val_loss: 93.9214 - val_mae: 0.1598\n",
      "Epoch 581/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 90.1216 - mae: 0.1567 - val_loss: 94.0810 - val_mae: 0.1585\n",
      "Epoch 582/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.1167 - mae: 0.1554 - val_loss: 93.8666 - val_mae: 0.1602\n",
      "Epoch 583/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 90.1109 - mae: 0.1571 - val_loss: 94.0915 - val_mae: 0.1584\n",
      "Epoch 584/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 90.1020 - mae: 0.1552 - val_loss: 93.8590 - val_mae: 0.1602\n",
      "Epoch 585/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 90.0955 - mae: 0.1571 - val_loss: 94.0851 - val_mae: 0.1584\n",
      "Epoch 586/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 90.0848 - mae: 0.1553 - val_loss: 93.8862 - val_mae: 0.1600\n",
      "Epoch 587/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 90.0743 - mae: 0.1569 - val_loss: 94.0588 - val_mae: 0.1587\n",
      "Epoch 588/20000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 90.0624 - mae: 0.1555 - val_loss: 93.9346 - val_mae: 0.1596\n",
      "Epoch 589/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 90.0532 - mae: 0.1565 - val_loss: 94.0540 - val_mae: 0.1587\n",
      "Epoch 590/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 90.0442 - mae: 0.1556 - val_loss: 93.9510 - val_mae: 0.1595\n",
      "Epoch 591/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 90.0347 - mae: 0.1563 - val_loss: 94.0459 - val_mae: 0.1587\n",
      "Epoch 592/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 90.0263 - mae: 0.1556 - val_loss: 93.9143 - val_mae: 0.1597\n",
      "Epoch 593/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 90.0201 - mae: 0.1566 - val_loss: 94.1170 - val_mae: 0.1582\n",
      "Epoch 594/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 90.0176 - mae: 0.1550 - val_loss: 93.8252 - val_mae: 0.1604\n",
      "Epoch 595/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 90.0233 - mae: 0.1573 - val_loss: 94.3044 - val_mae: 0.1570\n",
      "Epoch 596/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 90.0376 - mae: 0.1538 - val_loss: 93.6852 - val_mae: 0.1618\n",
      "Epoch 597/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 90.0912 - mae: 0.1588 - val_loss: 94.4954 - val_mae: 0.1560\n",
      "Epoch 598/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 90.0808 - mae: 0.1528 - val_loss: 93.6207 - val_mae: 0.1624\n",
      "Epoch 599/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.1150 - mae: 0.1594 - val_loss: 94.2973 - val_mae: 0.1568\n",
      "Epoch 600/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 90.0167 - mae: 0.1536 - val_loss: 93.7739 - val_mae: 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 89.9690 - mae: 0.1572 - val_loss: 93.9610 - val_mae: 0.1586\n",
      "Epoch 602/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 89.9420 - mae: 0.1555 - val_loss: 94.0104 - val_mae: 0.1582\n",
      "Epoch 603/20000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 89.9376 - mae: 0.1551 - val_loss: 93.7472 - val_mae: 0.1603\n",
      "Epoch 604/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 89.9492 - mae: 0.1572 - val_loss: 94.2537 - val_mae: 0.1568\n",
      "Epoch 605/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 89.9706 - mae: 0.1536 - val_loss: 93.5832 - val_mae: 0.1621\n",
      "Epoch 606/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.0432 - mae: 0.1591 - val_loss: 94.4954 - val_mae: 0.1555\n",
      "Epoch 607/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 90.0247 - mae: 0.1524 - val_loss: 93.5616 - val_mae: 0.1626\n",
      "Epoch 608/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 90.0813 - mae: 0.1596 - val_loss: 94.3413 - val_mae: 0.1564\n",
      "Epoch 609/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 89.9506 - mae: 0.1532 - val_loss: 93.8214 - val_mae: 0.1598\n",
      "Epoch 610/20000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 89.8901 - mae: 0.1567 - val_loss: 93.9550 - val_mae: 0.1588\n",
      "Epoch 611/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 89.8670 - mae: 0.1557 - val_loss: 94.1676 - val_mae: 0.1575\n",
      "Epoch 612/20000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 89.8782 - mae: 0.1543 - val_loss: 93.6852 - val_mae: 0.1611\n",
      "Epoch 613/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 89.9251 - mae: 0.1581 - val_loss: 94.5191 - val_mae: 0.1554\n",
      "Epoch 614/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 89.9657 - mae: 0.1523 - val_loss: 93.5318 - val_mae: 0.1634\n",
      "Epoch 615/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 90.1316 - mae: 0.1605 - val_loss: 94.5109 - val_mae: 0.1554\n",
      "Epoch 616/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 89.9438 - mae: 0.1523 - val_loss: 93.7279 - val_mae: 0.1604\n",
      "Epoch 617/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 89.8674 - mae: 0.1574 - val_loss: 94.0924 - val_mae: 0.1577\n",
      "Epoch 618/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 89.8268 - mae: 0.1546 - val_loss: 93.9243 - val_mae: 0.1588\n",
      "Epoch 619/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 89.8111 - mae: 0.1558 - val_loss: 93.8980 - val_mae: 0.1590\n",
      "Epoch 620/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 89.8028 - mae: 0.1559 - val_loss: 94.1615 - val_mae: 0.1573\n",
      "Epoch 621/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 89.8112 - mae: 0.1542 - val_loss: 93.7163 - val_mae: 0.1604\n",
      "Epoch 622/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 89.8384 - mae: 0.1574 - val_loss: 94.3912 - val_mae: 0.1558\n",
      "Epoch 623/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 89.8648 - mae: 0.1527 - val_loss: 93.5137 - val_mae: 0.1627\n",
      "Epoch 624/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 89.9934 - mae: 0.1598 - val_loss: 94.6002 - val_mae: 0.1547\n",
      "Epoch 625/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 89.9334 - mae: 0.1516 - val_loss: 93.4838 - val_mae: 0.1633\n",
      "Epoch 626/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 90.0677 - mae: 0.1605 - val_loss: 94.3092 - val_mae: 0.1561\n",
      "Epoch 627/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 89.8145 - mae: 0.1530 - val_loss: 94.1062 - val_mae: 0.1573\n",
      "Epoch 628/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 89.7646 - mae: 0.1542 - val_loss: 93.5740 - val_mae: 0.1617\n",
      "Epoch 629/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 89.8774 - mae: 0.1588 - val_loss: 94.7278 - val_mae: 0.1542\n",
      "Epoch 630/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 89.9629 - mae: 0.1511 - val_loss: 93.4744 - val_mae: 0.1649\n",
      "Epoch 631/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 90.2841 - mae: 0.1622 - val_loss: 94.2139 - val_mae: 0.1564\n",
      "Epoch 632/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 89.7667 - mae: 0.1534 - val_loss: 94.7669 - val_mae: 0.1537\n",
      "Epoch 633/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 89.9350 - mae: 0.1506 - val_loss: 93.5100 - val_mae: 0.1672\n",
      "Epoch 634/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 90.7161 - mae: 0.1647 - val_loss: 93.7104 - val_mae: 0.1597\n",
      "Epoch 635/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 89.7366 - mae: 0.1567 - val_loss: 98.2683 - val_mae: 0.1439\n",
      "Epoch 636/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 92.0222 - mae: 0.1411 - val_loss: 95.4596 - val_mae: 0.1766\n",
      "Epoch 637/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 94.4166 - mae: 0.1753 - val_loss: 96.9075 - val_mae: 0.1796\n",
      "Epoch 638/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 96.5101 - mae: 0.1787 - val_loss: 97.2954 - val_mae: 0.1801\n",
      "Epoch 639/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 97.0238 - mae: 0.1794 - val_loss: 97.1974 - val_mae: 0.1799\n",
      "Epoch 640/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 96.9264 - mae: 0.1792 - val_loss: 96.7227 - val_mae: 0.1791\n",
      "Epoch 641/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 96.3823 - mae: 0.1783 - val_loss: 95.8961 - val_mae: 0.1772\n",
      "Epoch 642/20000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 95.3825 - mae: 0.1764 - val_loss: 94.8450 - val_mae: 0.1732\n",
      "Epoch 643/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 93.9717 - mae: 0.1723 - val_loss: 94.4879 - val_mae: 0.1643\n",
      "Epoch 644/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.9806 - mae: 0.1633 - val_loss: 96.9846 - val_mae: 0.1515\n",
      "Epoch 645/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 94.6733 - mae: 0.1504 - val_loss: 95.1042 - val_mae: 0.1561\n",
      "Epoch 646/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 93.0880 - mae: 0.1549 - val_loss: 93.8406 - val_mae: 0.1631\n",
      "Epoch 647/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.4094 - mae: 0.1622 - val_loss: 93.5957 - val_mae: 0.1671\n",
      "Epoch 648/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 92.4905 - mae: 0.1663 - val_loss: 93.5866 - val_mae: 0.1691\n",
      "Epoch 649/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 92.6645 - mae: 0.1684 - val_loss: 93.5305 - val_mae: 0.1695\n",
      "Epoch 650/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.7021 - mae: 0.1687 - val_loss: 93.3564 - val_mae: 0.1684\n",
      "Epoch 651/20000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 92.5676 - mae: 0.1676 - val_loss: 93.2260 - val_mae: 0.1659\n",
      "Epoch 652/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 92.4311 - mae: 0.1652 - val_loss: 93.3103 - val_mae: 0.1629\n",
      "Epoch 653/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 92.5014 - mae: 0.1622 - val_loss: 93.4523 - val_mae: 0.1611\n",
      "Epoch 654/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 92.6476 - mae: 0.1603 - val_loss: 93.3435 - val_mae: 0.1618\n",
      "Epoch 655/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 92.5797 - mae: 0.1610 - val_loss: 93.1530 - val_mae: 0.1640\n",
      "Epoch 656/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.4610 - mae: 0.1633 - val_loss: 93.0966 - val_mae: 0.1662\n",
      "Epoch 657/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.4799 - mae: 0.1654 - val_loss: 93.1266 - val_mae: 0.1674\n",
      "Epoch 658/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.5416 - mae: 0.1666 - val_loss: 93.1245 - val_mae: 0.1673\n",
      "Epoch 659/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 92.5280 - mae: 0.1666 - val_loss: 93.0879 - val_mae: 0.1662\n",
      "Epoch 660/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 92.4342 - mae: 0.1654 - val_loss: 93.1053 - val_mae: 0.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.3544 - mae: 0.1636 - val_loss: 93.2014 - val_mae: 0.1626\n",
      "Epoch 662/20000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 92.3397 - mae: 0.1618 - val_loss: 93.2784 - val_mae: 0.1617\n",
      "Epoch 663/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 92.3213 - mae: 0.1608 - val_loss: 93.2598 - val_mae: 0.1619\n",
      "Epoch 664/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 92.2350 - mae: 0.1611 - val_loss: 93.1881 - val_mae: 0.1631\n",
      "Epoch 665/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 92.1299 - mae: 0.1622 - val_loss: 93.1546 - val_mae: 0.1643\n",
      "Epoch 666/20000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.0752 - mae: 0.1635 - val_loss: 93.1711 - val_mae: 0.1650\n",
      "Epoch 667/20000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 92.0497 - mae: 0.1642 - val_loss: 93.2079 - val_mae: 0.1649\n",
      "Epoch 668/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 92.0063 - mae: 0.1641 - val_loss: 93.2486 - val_mae: 0.1641\n",
      "Epoch 669/20000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 91.9406 - mae: 0.1633 - val_loss: 93.3243 - val_mae: 0.1629\n",
      "Epoch 670/20000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 91.8904 - mae: 0.1620 - val_loss: 93.4302 - val_mae: 0.1617\n",
      "Epoch 671/20000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 91.8771 - mae: 0.1609 - val_loss: 93.4936 - val_mae: 0.1612\n",
      "Epoch 672/20000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 91.8660 - mae: 0.1603 - val_loss: 93.4828 - val_mae: 0.1614\n",
      "Epoch 673/20000\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 91.8342 - mae: 0.1605 - val_loss: 93.4212 - val_mae: 0.1621\n",
      "Epoch 674/20000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 91.7964 - mae: 0.1613 - val_loss: 93.3536 - val_mae: 0.1629\n",
      "Epoch 675/20000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 91.7709 - mae: 0.1620 - val_loss: 93.3028 - val_mae: 0.1633\n",
      "Epoch 676/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.7483 - mae: 0.1624 - val_loss: 93.2704 - val_mae: 0.1631\n",
      "Epoch 677/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.7113 - mae: 0.1623 - val_loss: 93.2574 - val_mae: 0.1625\n",
      "Epoch 678/20000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 91.6639 - mae: 0.1617 - val_loss: 93.2653 - val_mae: 0.1617\n",
      "Epoch 679/20000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 91.6257 - mae: 0.1608 - val_loss: 93.2729 - val_mae: 0.1611\n",
      "Epoch 680/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.5975 - mae: 0.1602 - val_loss: 93.2457 - val_mae: 0.1609\n",
      "Epoch 681/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 91.5654 - mae: 0.1600 - val_loss: 93.1823 - val_mae: 0.1613\n",
      "Epoch 682/20000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 91.5284 - mae: 0.1603 - val_loss: 93.1114 - val_mae: 0.1618\n",
      "Epoch 683/20000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 91.4971 - mae: 0.1609 - val_loss: 93.0566 - val_mae: 0.1622\n",
      "Epoch 684/20000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 91.4736 - mae: 0.1613 - val_loss: 93.0248 - val_mae: 0.1624\n",
      "Epoch 685/20000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 91.4511 - mae: 0.1614 - val_loss: 93.0199 - val_mae: 0.1621\n",
      "Epoch 686/20000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 91.4221 - mae: 0.1611 - val_loss: 93.0433 - val_mae: 0.1615\n",
      "Epoch 687/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.3905 - mae: 0.1605 - val_loss: 93.0746 - val_mae: 0.1610\n",
      "Epoch 688/20000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 91.3621 - mae: 0.1599 - val_loss: 93.0901 - val_mae: 0.1607\n",
      "Epoch 689/20000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 91.3306 - mae: 0.1596 - val_loss: 93.0686 - val_mae: 0.1608\n",
      "Epoch 690/20000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 91.2894 - mae: 0.1597 - val_loss: 93.0345 - val_mae: 0.1611\n",
      "Epoch 691/20000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 91.2467 - mae: 0.1600 - val_loss: 93.0075 - val_mae: 0.1614\n",
      "Epoch 692/20000\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 91.2075 - mae: 0.1603 - val_loss: 92.9983 - val_mae: 0.1614\n",
      "Epoch 693/20000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 91.1668 - mae: 0.1603 - val_loss: 93.0092 - val_mae: 0.1611\n",
      "Epoch 694/20000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 91.1227 - mae: 0.1599 - val_loss: 93.0339 - val_mae: 0.1605\n",
      "Epoch 695/20000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 91.0770 - mae: 0.1593 - val_loss: 93.0540 - val_mae: 0.1601\n",
      "Epoch 696/20000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 91.0360 - mae: 0.1588 - val_loss: 93.0450 - val_mae: 0.1599\n",
      "Epoch 697/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.9918 - mae: 0.1586 - val_loss: 93.0037 - val_mae: 0.1600\n",
      "Epoch 698/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.9432 - mae: 0.1588 - val_loss: 92.9570 - val_mae: 0.1603\n",
      "Epoch 699/20000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 90.8978 - mae: 0.1590 - val_loss: 92.9255 - val_mae: 0.1604\n",
      "Epoch 700/20000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 90.8518 - mae: 0.1590 - val_loss: 92.9199 - val_mae: 0.1602\n",
      "Epoch 701/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 90.8040 - mae: 0.1588 - val_loss: 92.9339 - val_mae: 0.1598\n",
      "Epoch 702/20000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 90.7555 - mae: 0.1583 - val_loss: 92.9468 - val_mae: 0.1594\n",
      "Epoch 703/20000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 90.7058 - mae: 0.1579 - val_loss: 92.9412 - val_mae: 0.1592\n",
      "Epoch 704/20000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 90.6574 - mae: 0.1576 - val_loss: 92.9083 - val_mae: 0.1593\n",
      "Epoch 705/20000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 90.6065 - mae: 0.1576 - val_loss: 92.8738 - val_mae: 0.1594\n",
      "Epoch 706/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 90.5566 - mae: 0.1577 - val_loss: 92.8595 - val_mae: 0.1594\n",
      "Epoch 707/20000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 90.5069 - mae: 0.1576 - val_loss: 92.8759 - val_mae: 0.1590\n",
      "Epoch 708/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 90.4556 - mae: 0.1572 - val_loss: 92.8995 - val_mae: 0.1586\n",
      "Epoch 709/20000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 90.4069 - mae: 0.1566 - val_loss: 92.8929 - val_mae: 0.1585\n",
      "Epoch 710/20000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 90.3560 - mae: 0.1565 - val_loss: 92.8717 - val_mae: 0.1587\n",
      "Epoch 711/20000\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 90.3056 - mae: 0.1566 - val_loss: 92.8721 - val_mae: 0.1588\n",
      "Epoch 712/20000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 90.2607 - mae: 0.1566 - val_loss: 92.8941 - val_mae: 0.1586\n",
      "Epoch 713/20000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 90.2159 - mae: 0.1564 - val_loss: 92.9430 - val_mae: 0.1582\n",
      "Epoch 714/20000\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 90.1719 - mae: 0.1559 - val_loss: 92.9764 - val_mae: 0.1581\n",
      "Epoch 715/20000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 90.1268 - mae: 0.1558 - val_loss: 93.0077 - val_mae: 0.1582\n",
      "Epoch 716/20000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 90.0821 - mae: 0.1559 - val_loss: 93.0602 - val_mae: 0.1581\n",
      "Epoch 717/20000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 90.0426 - mae: 0.1557 - val_loss: 93.1251 - val_mae: 0.1579\n",
      "Epoch 718/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 90.0081 - mae: 0.1554 - val_loss: 93.1425 - val_mae: 0.1581\n",
      "Epoch 719/20000\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 89.9763 - mae: 0.1556 - val_loss: 93.1729 - val_mae: 0.1582\n",
      "Epoch 720/20000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 89.9496 - mae: 0.1557 - val_loss: 93.2684 - val_mae: 0.1578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 89.9256 - mae: 0.1552 - val_loss: 93.3017 - val_mae: 0.1580\n",
      "Epoch 722/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 89.9027 - mae: 0.1554 - val_loss: 93.3009 - val_mae: 0.1585\n",
      "Epoch 723/20000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 89.8838 - mae: 0.1560 - val_loss: 93.4307 - val_mae: 0.1579\n",
      "Epoch 724/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 89.8647 - mae: 0.1554 - val_loss: 93.5024 - val_mae: 0.1578\n",
      "Epoch 725/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 89.8510 - mae: 0.1553 - val_loss: 93.5282 - val_mae: 0.1580\n",
      "Epoch 726/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 89.8397 - mae: 0.1555 - val_loss: 93.5820 - val_mae: 0.1579\n",
      "Epoch 727/20000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 89.8267 - mae: 0.1554 - val_loss: 93.6592 - val_mae: 0.1575\n",
      "Epoch 728/20000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 89.8144 - mae: 0.1550 - val_loss: 93.6186 - val_mae: 0.1580\n",
      "Epoch 729/20000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 89.7988 - mae: 0.1555 - val_loss: 93.6115 - val_mae: 0.1581\n",
      "Epoch 730/20000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 89.7852 - mae: 0.1556 - val_loss: 93.7075 - val_mae: 0.1574\n",
      "Epoch 731/20000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 89.7706 - mae: 0.1550 - val_loss: 93.6774 - val_mae: 0.1576\n",
      "Epoch 732/20000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 89.7548 - mae: 0.1552 - val_loss: 93.6382 - val_mae: 0.1580\n",
      "Epoch 733/20000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 89.7417 - mae: 0.1556 - val_loss: 93.7345 - val_mae: 0.1574\n",
      "Epoch 734/20000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 89.7275 - mae: 0.1550 - val_loss: 93.7342 - val_mae: 0.1574\n",
      "Epoch 735/20000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 89.7151 - mae: 0.1551 - val_loss: 93.6968 - val_mae: 0.1578\n",
      "Epoch 736/20000\n",
      "1/1 [==============================] - ETA: 0s - loss: 89.7035 - mae: 0.1554"
     ]
    }
   ],
   "source": [
    "model = build_model ()\n",
    "history = model.fit ( x_train, y_train, epochs = 20000, batch_size = 500000 , validation_data = (x_val, y_val) )\n",
    "model.save(\"../models/classifier/{}_noposition.h5\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "accuracy = history.history['mae']\n",
    "val_accuracy = history.history['val_mae']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "l1 = ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "vl1 = ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss (mae))')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ac2= ax2.plot(epochs, accuracy, 'o', c=\"red\", label='Training acc')\n",
    "vac2= ax2.plot(epochs, val_accuracy, 'r', label='Validation acc')\n",
    "ax2.set_ylabel('mape')\n",
    "\n",
    "lns = l1 + vl1 + ac2 + vac2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=\"center right\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"acc+loss_drop.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "accuracy = history.history['mae']\n",
    "val_accuracy = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(prob_array, bins):\n",
    "    prob_array = np.array(prob_array)\n",
    "    plt.hist(prob_array, bins, histtype=u'step', density=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "y = np.array(y)\n",
    "bins = np.linspace(0, 0.6, 100)\n",
    "pyplot.hist(y, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "pyplot.hist(y_pred, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.title('Trained on ($p_e$, $p_{\\gamma}$, $\\omega_e$, $\\omega_{\\gamma}$, n)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
