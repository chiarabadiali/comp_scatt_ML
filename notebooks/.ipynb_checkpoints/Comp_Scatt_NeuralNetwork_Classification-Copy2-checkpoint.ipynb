{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "print(pd.__version__)\n",
    "import progressbar\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Dependencies\n",
    "\n",
    "\n",
    "\n",
    "Dependences are fundamental to record the computational environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "pandas    : 1.2.3\n",
      "keras     : 2.4.3\n",
      "numpy     : 1.19.5\n",
      "math      : unknown\n",
      "tensorflow: 2.4.1\n",
      "matplotlib: not installed\n",
      "h5py      : 2.10.0\n",
      "\n",
      "Compiler    : Clang 12.0.0 (clang-1200.0.32.29)\n",
      "OS          : Darwin\n",
      "Release     : 19.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      " \n",
      "Last updated: Tue Mar 30 2021 14:08:10CEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p pandas,keras,numpy,math,tensorflow,matplotlib,h5py\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of the data\n",
    "\n",
    "   You can also load all of them! Writing \"all_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import loaddata\n",
    "class_data = loaddata(\"../data/{}.csv\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = class_data[class_data[:,0] > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(class_data)\n",
    "y = class_data[:,0]\n",
    "#y2 = class_data[:,-1]\n",
    "x = class_data[:,1:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20746096689629911"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.28377189e-01, -1.84104467e-01,  8.00204362e-01, -3.30019048e-01,\n",
       "        5.31816209e-01,  1.06882542e-01,  3.06000000e+00,  3.93999998e+09,\n",
       "       -4.09324611e-01,  1.37670373e-01, -5.39737149e-04,  4.30267198e-01,\n",
       "        5.56999932e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y2.shape)\n",
    "#print(y1.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135911, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample: 101933 \n",
      "Valuation sample: 33978\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.75\n",
    "train_limit = int(len(y)*train_split)\n",
    "print(\"Training sample: {0} \\nValuation sample: {1}\".format(train_limit, len(y)-train_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:train_limit]\n",
    "x_val = x[train_limit:]\n",
    "\n",
    "y_train = y[:train_limit]\n",
    "y_val = y[train_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def root_mean_squared_log_error(y, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(1+y_pred) - K.log(1+y))))\n",
    "\n",
    "def maape(y, y_pred):\n",
    "    return K.mean(K.mean(tf.math.atan(K.abs((y-y_pred)/y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add (BatchNormalization(input_dim = 13))\n",
    "    model.add (layers.Dense (16 , activation = \"sigmoid\"))\n",
    "    model.add (layers.Dense (32, activation = \"relu\"))\n",
    "    model.add (layers.Dense (64 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (128 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (64, activation = \"relu\"))\n",
    "    model.add (layers.Dense (32 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (16, activation = \"relu\"))\n",
    "    model.add (layers.Dense (12 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (1 , activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\" , loss = maape , metrics = [\"mape\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "2/2 [==============================] - 2s 528ms/step - loss: 1.0349 - mape: 740.8418 - val_loss: 1.0171 - val_mape: 754.2380\n",
      "Epoch 2/10000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0191 - mape: 722.4427 - val_loss: 1.0016 - val_mape: 737.8022\n",
      "Epoch 3/10000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0085 - mape: 710.7809 - val_loss: 0.9847 - val_mape: 720.7648\n",
      "Epoch 4/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9963 - mape: 696.5256 - val_loss: 0.9624 - val_mape: 697.4182\n",
      "Epoch 5/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9790 - mape: 678.7534 - val_loss: 0.9277 - val_mape: 667.3628\n",
      "Epoch 6/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.9552 - mape: 653.5085 - val_loss: 0.8812 - val_mape: 628.5167\n",
      "Epoch 7/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.9214 - mape: 622.4125 - val_loss: 0.8176 - val_mape: 580.6495\n",
      "Epoch 8/10000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8739 - mape: 581.3054 - val_loss: 0.7289 - val_mape: 520.2770\n",
      "Epoch 9/10000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.8058 - mape: 528.7744 - val_loss: 0.6111 - val_mape: 446.1620\n",
      "Epoch 10/10000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7086 - mape: 462.0904 - val_loss: 0.4940 - val_mape: 361.5275\n",
      "Epoch 11/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5813 - mape: 381.0014 - val_loss: 0.4575 - val_mape: 277.9887\n",
      "Epoch 12/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4744 - mape: 292.2267 - val_loss: 0.5086 - val_mape: 210.2437\n",
      "Epoch 13/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4597 - mape: 217.2620 - val_loss: 0.5613 - val_mape: 171.0527\n",
      "Epoch 14/10000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4970 - mape: 174.4455 - val_loss: 0.5794 - val_mape: 157.1069\n",
      "Epoch 15/10000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5185 - mape: 158.1991 - val_loss: 0.5720 - val_mape: 157.8059\n",
      "Epoch 16/10000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5149 - mape: 157.6256 - val_loss: 0.5446 - val_mape: 169.1743\n",
      "Epoch 17/10000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4931 - mape: 168.3714 - val_loss: 0.5059 - val_mape: 189.7321\n",
      "Epoch 18/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4655 - mape: 188.6270 - val_loss: 0.4696 - val_mape: 216.9773\n",
      "Epoch 19/10000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4467 - mape: 214.6546 - val_loss: 0.4507 - val_mape: 243.4304\n",
      "Epoch 20/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4449 - mape: 239.1104 - val_loss: 0.4469 - val_mape: 259.9650\n",
      "Epoch 21/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4498 - mape: 252.4524 - val_loss: 0.4464 - val_mape: 262.5586\n",
      "Epoch 22/10000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.4490 - mape: 251.5376 - val_loss: 0.4433 - val_mape: 251.5791\n",
      "Epoch 23/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.4409 - mape: 236.9702 - val_loss: 0.4388 - val_mape: 231.5657\n",
      "Epoch 24/10000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.4319 - mape: 214.6331 - val_loss: 0.4351 - val_mape: 209.5287\n",
      "Epoch 25/10000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.4290 - mape: 192.0747 - val_loss: 0.4316 - val_mape: 192.7733\n",
      "Epoch 26/10000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4307 - mape: 174.9984 - val_loss: 0.4269 - val_mape: 186.0742\n",
      "Epoch 27/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4304 - mape: 167.7838 - val_loss: 0.4224 - val_mape: 190.2854\n",
      "Epoch 28/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4246 - mape: 169.3941 - val_loss: 0.4220 - val_mape: 200.9146\n",
      "Epoch 29/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4188 - mape: 177.4138 - val_loss: 0.4252 - val_mape: 209.8163\n",
      "Epoch 30/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4156 - mape: 182.6584 - val_loss: 0.4277 - val_mape: 212.1812\n",
      "Epoch 31/10000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.4132 - mape: 182.4568 - val_loss: 0.4261 - val_mape: 206.5480\n",
      "Epoch 32/10000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.4096 - mape: 175.3073 - val_loss: 0.4207 - val_mape: 195.7758\n",
      "Epoch 33/10000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.4056 - mape: 164.1413 - val_loss: 0.4162 - val_mape: 186.3570\n",
      "Epoch 34/10000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4023 - mape: 154.6418 - val_loss: 0.4153 - val_mape: 181.1671\n",
      "Epoch 35/10000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3985 - mape: 147.9806 - val_loss: 0.4183 - val_mape: 179.1528\n",
      "Epoch 36/10000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3941 - mape: 144.3015 - val_loss: 0.4217 - val_mape: 176.2987\n",
      "Epoch 37/10000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3893 - mape: 139.6901 - val_loss: 0.4232 - val_mape: 171.2745\n",
      "Epoch 38/10000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3842 - mape: 133.3914 - val_loss: 0.4216 - val_mape: 163.2821\n",
      "Epoch 39/10000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3785 - mape: 125.3622 - val_loss: 0.4166 - val_mape: 152.9322\n",
      "Epoch 40/10000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3725 - mape: 115.5787 - val_loss: 0.4171 - val_mape: 145.6807\n",
      "Epoch 41/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3659 - mape: 109.0896 - val_loss: 0.4185 - val_mape: 140.2630\n",
      "Epoch 42/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.3591 - mape: 102.6338 - val_loss: 0.4156 - val_mape: 133.0472\n",
      "Epoch 43/10000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3522 - mape: 95.4142 - val_loss: 0.4064 - val_mape: 122.5791\n",
      "Epoch 44/10000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.3452 - mape: 86.8582 - val_loss: 0.3962 - val_mape: 112.3927\n",
      "Epoch 45/10000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3394 - mape: 79.2156 - val_loss: 0.4045 - val_mape: 113.0568\n",
      "Epoch 46/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3327 - mape: 77.3326 - val_loss: 0.3986 - val_mape: 107.0769\n",
      "Epoch 47/10000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.3272 - mape: 72.6229 - val_loss: 0.3806 - val_mape: 95.9587\n",
      "Epoch 48/10000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3224 - mape: 66.0229 - val_loss: 0.3883 - val_mape: 97.8794\n",
      "Epoch 49/10000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.3168 - mape: 65.0593 - val_loss: 0.3802 - val_mape: 92.1111\n",
      "Epoch 50/10000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3116 - mape: 61.2789 - val_loss: 0.3645 - val_mape: 83.2507\n",
      "Epoch 51/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3081 - mape: 56.7078 - val_loss: 0.3822 - val_mape: 90.2185\n",
      "Epoch 52/10000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3060 - mape: 58.6381 - val_loss: 0.3688 - val_mape: 82.2899\n",
      "Epoch 53/10000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3022 - mape: 54.8135 - val_loss: 0.3548 - val_mape: 74.8715\n",
      "Epoch 54/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3012 - mape: 51.7305 - val_loss: 0.3689 - val_mape: 79.7435\n",
      "Epoch 55/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2988 - mape: 52.7221 - val_loss: 0.3605 - val_mape: 75.0508\n",
      "Epoch 56/10000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.2972 - mape: 50.5744 - val_loss: 0.3545 - val_mape: 71.9201\n",
      "Epoch 57/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2965 - mape: 49.2273 - val_loss: 0.3756 - val_mape: 80.0633\n",
      "Epoch 58/10000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2971 - mape: 51.8195 - val_loss: 0.3626 - val_mape: 74.1736\n",
      "Epoch 59/10000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.2943 - mape: 49.3331 - val_loss: 0.3456 - val_mape: 67.2761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2948 - mape: 47.0738 - val_loss: 0.3723 - val_mape: 77.8824\n",
      "Epoch 61/10000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2953 - mape: 50.4146 - val_loss: 0.3643 - val_mape: 74.1360\n",
      "Epoch 62/10000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2927 - mape: 48.7091 - val_loss: 0.3338 - val_mape: 62.8343\n",
      "Epoch 63/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2951 - mape: 45.5099 - val_loss: 0.3590 - val_mape: 71.2749\n",
      "Epoch 64/10000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2914 - mape: 47.4419 - val_loss: 0.3681 - val_mape: 74.8248\n",
      "Epoch 65/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2926 - mape: 48.2713 - val_loss: 0.3365 - val_mape: 64.0389\n",
      "Epoch 66/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2914 - mape: 45.1401 - val_loss: 0.3493 - val_mape: 68.7781\n",
      "Epoch 67/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2897 - mape: 46.4455 - val_loss: 0.3616 - val_mape: 73.9416\n",
      "Epoch 68/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2921 - mape: 48.2820 - val_loss: 0.3279 - val_mape: 61.5742\n",
      "Epoch 69/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2911 - mape: 44.3271 - val_loss: 0.3320 - val_mape: 62.8027\n",
      "Epoch 70/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2887 - mape: 44.4569 - val_loss: 0.3518 - val_mape: 68.8646\n",
      "Epoch 71/10000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2881 - mape: 46.2240 - val_loss: 0.3210 - val_mape: 58.7035\n",
      "Epoch 72/10000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2903 - mape: 43.2991 - val_loss: 0.3256 - val_mape: 59.8117\n",
      "Epoch 73/10000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.2877 - mape: 43.2562 - val_loss: 0.3601 - val_mape: 71.3607\n",
      "Epoch 74/10000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.2912 - mape: 47.3520 - val_loss: 0.3413 - val_mape: 64.5096\n",
      "Epoch 75/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2864 - mape: 44.6118 - val_loss: 0.3172 - val_mape: 56.1479\n",
      "Epoch 76/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2883 - mape: 42.0889 - val_loss: 0.3273 - val_mape: 59.2070\n",
      "Epoch 77/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2848 - mape: 42.7629 - val_loss: 0.3324 - val_mape: 60.3285\n",
      "Epoch 78/10000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2843 - mape: 42.9652 - val_loss: 0.3346 - val_mape: 60.4729\n",
      "Epoch 79/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2845 - mape: 43.0970 - val_loss: 0.3305 - val_mape: 58.8589\n",
      "Epoch 80/10000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2840 - mape: 42.4869 - val_loss: 0.3251 - val_mape: 57.1186\n",
      "Epoch 81/10000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2831 - mape: 41.8685 - val_loss: 0.3222 - val_mape: 56.0192\n",
      "Epoch 82/10000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2825 - mape: 41.4363 - val_loss: 0.3265 - val_mape: 57.0656\n",
      "Epoch 83/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2820 - mape: 41.6952 - val_loss: 0.3395 - val_mape: 60.9437\n",
      "Epoch 84/10000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2842 - mape: 43.0934 - val_loss: 0.3140 - val_mape: 52.7480\n",
      "Epoch 85/10000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2823 - mape: 40.2530 - val_loss: 0.3205 - val_mape: 54.5313\n",
      "Epoch 86/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2807 - mape: 40.6949 - val_loss: 0.3389 - val_mape: 59.6676\n",
      "Epoch 87/10000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2833 - mape: 42.5627 - val_loss: 0.3157 - val_mape: 52.8551\n",
      "Epoch 88/10000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2800 - mape: 40.1621 - val_loss: 0.3066 - val_mape: 50.0711\n",
      "Epoch 89/10000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2811 - mape: 39.4871 - val_loss: 0.3295 - val_mape: 56.5840\n",
      "Epoch 90/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2804 - mape: 41.5963 - val_loss: 0.3305 - val_mape: 56.4870\n",
      "Epoch 91/10000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2804 - mape: 41.5621 - val_loss: 0.3043 - val_mape: 48.5430\n",
      "Epoch 92/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2797 - mape: 38.8165 - val_loss: 0.3159 - val_mape: 51.5451\n",
      "Epoch 93/10000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2778 - mape: 39.6622 - val_loss: 0.3230 - val_mape: 52.5874\n",
      "Epoch 94/10000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.2782 - mape: 40.0783 - val_loss: 0.3075 - val_mape: 48.1304\n",
      "Epoch 95/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2774 - mape: 38.6179 - val_loss: 0.2987 - val_mape: 45.4513\n",
      "Epoch 96/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2792 - mape: 37.9166 - val_loss: 0.3271 - val_mape: 53.0149\n",
      "Epoch 97/10000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2787 - mape: 40.4328 - val_loss: 0.3054 - val_mape: 46.7710\n",
      "Epoch 98/10000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.2764 - mape: 38.1035 - val_loss: 0.2890 - val_mape: 42.0052\n",
      "Epoch 99/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2835 - mape: 37.3619 - val_loss: 0.3168 - val_mape: 49.5315\n",
      "Epoch 100/10000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2757 - mape: 38.9493 - val_loss: 0.3181 - val_mape: 49.8769\n",
      "Epoch 101/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2758 - mape: 39.1680 - val_loss: 0.3108 - val_mape: 47.8263\n",
      "Epoch 102/10000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.2740 - mape: 38.2810 - val_loss: 0.3075 - val_mape: 46.7982\n",
      "Epoch 103/10000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2735 - mape: 37.8693 - val_loss: 0.3001 - val_mape: 44.7632\n",
      "Epoch 104/10000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2736 - mape: 37.1980 - val_loss: 0.3141 - val_mape: 48.4900\n",
      "Epoch 105/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2737 - mape: 38.5714 - val_loss: 0.3124 - val_mape: 48.1524\n",
      "Epoch 106/10000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2734 - mape: 38.4564 - val_loss: 0.3039 - val_mape: 45.8492\n",
      "Epoch 107/10000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2722 - mape: 37.5589 - val_loss: 0.3205 - val_mape: 49.8267\n",
      "Epoch 108/10000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2747 - mape: 39.2475 - val_loss: 0.3020 - val_mape: 44.5613\n",
      "Epoch 109/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2725 - mape: 37.0565 - val_loss: 0.2923 - val_mape: 42.1137\n",
      "Epoch 110/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2733 - mape: 36.4265 - val_loss: 0.3189 - val_mape: 49.2491\n",
      "Epoch 111/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2738 - mape: 39.0039 - val_loss: 0.3035 - val_mape: 45.4233\n",
      "Epoch 112/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2698 - mape: 37.2111 - val_loss: 0.2838 - val_mape: 39.9650\n",
      "Epoch 113/10000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2748 - mape: 35.8589 - val_loss: 0.3092 - val_mape: 46.2005\n",
      "Epoch 114/10000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2703 - mape: 37.4544 - val_loss: 0.3099 - val_mape: 46.0573\n",
      "Epoch 115/10000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2702 - mape: 37.3304 - val_loss: 0.2865 - val_mape: 40.1937\n",
      "Epoch 116/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2707 - mape: 35.4419 - val_loss: 0.2974 - val_mape: 42.8749\n",
      "Epoch 117/10000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2675 - mape: 35.9958 - val_loss: 0.3263 - val_mape: 50.0473\n",
      "Epoch 118/10000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2770 - mape: 39.5688 - val_loss: 0.2834 - val_mape: 38.8314\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2709 - mape: 34.6301 - val_loss: 0.2886 - val_mape: 40.0411\n",
      "Epoch 120/10000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2673 - mape: 35.0311 - val_loss: 0.3219 - val_mape: 47.7819\n",
      "Epoch 121/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2734 - mape: 38.2160 - val_loss: 0.2800 - val_mape: 37.3288\n",
      "Epoch 122/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2722 - mape: 34.4681 - val_loss: 0.2906 - val_mape: 40.1683\n",
      "Epoch 123/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2653 - mape: 34.7697 - val_loss: 0.3293 - val_mape: 49.7613\n",
      "Epoch 124/10000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2792 - mape: 39.6330 - val_loss: 0.2814 - val_mape: 37.5594\n",
      "Epoch 125/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2677 - mape: 34.0036 - val_loss: 0.2816 - val_mape: 37.4138\n",
      "Epoch 126/10000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2678 - mape: 33.9754 - val_loss: 0.3207 - val_mape: 46.7193\n",
      "Epoch 127/10000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2734 - mape: 37.7721 - val_loss: 0.2903 - val_mape: 39.8477\n",
      "Epoch 128/10000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2635 - mape: 34.3787 - val_loss: 0.2809 - val_mape: 37.5141\n",
      "Epoch 129/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2652 - mape: 33.6853 - val_loss: 0.3150 - val_mape: 45.7618\n",
      "Epoch 130/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2711 - mape: 37.3480 - val_loss: 0.3118 - val_mape: 44.0188\n",
      "Epoch 131/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2684 - mape: 36.3086 - val_loss: 0.2820 - val_mape: 36.6802\n",
      "Epoch 132/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2662 - mape: 33.5631 - val_loss: 0.2872 - val_mape: 38.2490\n",
      "Epoch 133/10000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.2625 - mape: 33.7886 - val_loss: 0.2963 - val_mape: 40.8893\n",
      "Epoch 134/10000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2632 - mape: 34.9214 - val_loss: 0.2829 - val_mape: 37.5823\n",
      "Epoch 135/10000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2621 - mape: 33.5912 - val_loss: 0.3105 - val_mape: 44.0834\n",
      "Epoch 136/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2693 - mape: 36.7033 - val_loss: 0.2784 - val_mape: 35.8419\n",
      "Epoch 137/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2639 - mape: 33.0511 - val_loss: 0.2870 - val_mape: 37.2849\n",
      "Epoch 138/10000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2640 - mape: 33.5168 - val_loss: 0.3288 - val_mape: 46.4208\n",
      "Epoch 139/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2804 - mape: 38.4503 - val_loss: 0.2751 - val_mape: 34.9245\n",
      "Epoch 140/10000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2661 - mape: 33.0550 - val_loss: 0.2729 - val_mape: 34.6237\n",
      "Epoch 141/10000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2678 - mape: 33.1353 - val_loss: 0.3298 - val_mape: 50.9257\n",
      "Epoch 142/10000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2909 - mape: 42.8527 - val_loss: 0.2970 - val_mape: 41.6740\n",
      "Epoch 143/10000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2646 - mape: 35.8821 - val_loss: 0.2751 - val_mape: 33.6053\n",
      "Epoch 144/10000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2838 - mape: 34.1549 - val_loss: 0.2901 - val_mape: 38.8755\n",
      "Epoch 145/10000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2626 - mape: 34.5310 - val_loss: 0.3215 - val_mape: 45.2335\n",
      "Epoch 146/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2790 - mape: 38.4405 - val_loss: 0.2789 - val_mape: 35.5503\n",
      "Epoch 147/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2687 - mape: 33.7182 - val_loss: 0.2734 - val_mape: 34.3793\n",
      "Epoch 148/10000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2713 - mape: 33.5918 - val_loss: 0.2885 - val_mape: 39.7331\n",
      "Epoch 149/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2608 - mape: 34.8974 - val_loss: 0.2978 - val_mape: 42.2832\n",
      "Epoch 150/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2652 - mape: 36.4964 - val_loss: 0.2722 - val_mape: 34.8121\n",
      "Epoch 151/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2656 - mape: 33.4976 - val_loss: 0.2733 - val_mape: 34.5068\n",
      "Epoch 152/10000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2663 - mape: 33.2227 - val_loss: 0.3025 - val_mape: 42.0148\n",
      "Epoch 153/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2668 - mape: 36.5149 - val_loss: 0.3004 - val_mape: 41.6921\n",
      "Epoch 154/10000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2655 - mape: 36.2949 - val_loss: 0.2720 - val_mape: 34.4898\n",
      "Epoch 155/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2630 - mape: 32.8798 - val_loss: 0.2742 - val_mape: 35.6129\n",
      "Epoch 156/10000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2588 - mape: 33.0754 - val_loss: 0.2927 - val_mape: 40.4390\n",
      "Epoch 157/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2618 - mape: 35.5003 - val_loss: 0.2811 - val_mape: 37.5040\n",
      "Epoch 158/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2573 - mape: 33.7236 - val_loss: 0.2749 - val_mape: 35.7824\n",
      "Epoch 159/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2572 - mape: 32.9463 - val_loss: 0.2794 - val_mape: 36.8979\n",
      "Epoch 160/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2563 - mape: 33.3714 - val_loss: 0.2978 - val_mape: 41.1140\n",
      "Epoch 161/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2639 - mape: 35.8557 - val_loss: 0.2795 - val_mape: 36.5914\n",
      "Epoch 162/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2559 - mape: 33.1163 - val_loss: 0.2711 - val_mape: 34.0488\n",
      "Epoch 163/10000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.2588 - mape: 32.1519 - val_loss: 0.2779 - val_mape: 36.2370\n",
      "Epoch 164/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2550 - mape: 32.8590 - val_loss: 0.2828 - val_mape: 37.4587\n",
      "Epoch 165/10000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.2559 - mape: 33.5007 - val_loss: 0.2719 - val_mape: 34.5398\n",
      "Epoch 166/10000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2551 - mape: 32.0568 - val_loss: 0.2719 - val_mape: 34.3953\n",
      "Epoch 167/10000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2548 - mape: 31.9322 - val_loss: 0.2780 - val_mape: 35.9058\n",
      "Epoch 168/10000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2538 - mape: 32.4784 - val_loss: 0.2806 - val_mape: 36.4472\n",
      "Epoch 169/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2544 - mape: 32.7601 - val_loss: 0.2726 - val_mape: 34.4727\n",
      "Epoch 170/10000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2533 - mape: 31.7326 - val_loss: 0.2695 - val_mape: 33.5511\n",
      "Epoch 171/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2549 - mape: 31.4860 - val_loss: 0.3063 - val_mape: 41.8556\n",
      "Epoch 172/10000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2697 - mape: 36.4545 - val_loss: 0.2853 - val_mape: 36.7938\n",
      "Epoch 173/10000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2575 - mape: 33.0504 - val_loss: 0.2723 - val_mape: 32.5819\n",
      "Epoch 174/10000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2662 - mape: 31.8644 - val_loss: 0.2716 - val_mape: 33.9752\n",
      "Epoch 175/10000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2527 - mape: 31.4641 - val_loss: 0.2953 - val_mape: 39.8575\n",
      "Epoch 176/10000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2621 - mape: 35.0763 - val_loss: 0.2674 - val_mape: 32.5940\n",
      "Epoch 177/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2566 - mape: 31.1860 - val_loss: 0.2684 - val_mape: 32.2680\n",
      "Epoch 178/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2595 - mape: 31.2001 - val_loss: 0.3086 - val_mape: 41.9029\n",
      "Epoch 179/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2725 - mape: 36.7980 - val_loss: 0.2896 - val_mape: 37.8035\n",
      "Epoch 180/10000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2583 - mape: 33.6404 - val_loss: 0.2719 - val_mape: 31.8736\n",
      "Epoch 181/10000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2693 - mape: 31.5702 - val_loss: 0.2669 - val_mape: 32.1632\n",
      "Epoch 182/10000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.2556 - mape: 30.8321 - val_loss: 0.2939 - val_mape: 38.7878\n",
      "Epoch 183/10000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2611 - mape: 34.2092 - val_loss: 0.2716 - val_mape: 33.7377\n",
      "Epoch 184/10000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2508 - mape: 31.0822 - val_loss: 0.2672 - val_mape: 31.6290\n",
      "Epoch 185/10000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2597 - mape: 30.7176 - val_loss: 0.2752 - val_mape: 34.8444\n",
      "Epoch 186/10000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2508 - mape: 31.7028 - val_loss: 0.2923 - val_mape: 38.7007\n",
      "Epoch 187/10000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2609 - mape: 34.4147 - val_loss: 0.2679 - val_mape: 32.9165\n",
      "Epoch 188/10000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2495 - mape: 30.6028 - val_loss: 0.2688 - val_mape: 33.1320\n",
      "Epoch 189/10000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.2489 - mape: 30.6921 - val_loss: 0.2946 - val_mape: 38.6546\n",
      "Epoch 190/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2624 - mape: 34.3744 - val_loss: 0.2700 - val_mape: 32.9524\n",
      "Epoch 191/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2498 - mape: 30.5182 - val_loss: 0.2676 - val_mape: 31.3846\n",
      "Epoch 192/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2576 - mape: 30.2739 - val_loss: 0.2736 - val_mape: 33.9995\n",
      "Epoch 193/10000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2493 - mape: 30.9913 - val_loss: 0.2941 - val_mape: 38.6280\n",
      "Epoch 194/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2622 - mape: 34.3942 - val_loss: 0.2724 - val_mape: 33.9560\n",
      "Epoch 195/10000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2487 - mape: 31.0131 - val_loss: 0.2641 - val_mape: 31.2811\n",
      "Epoch 196/10000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2527 - mape: 29.9183 - val_loss: 0.2644 - val_mape: 31.8258\n",
      "Epoch 197/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2484 - mape: 29.9092 - val_loss: 0.2853 - val_mape: 36.7984\n",
      "Epoch 198/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2553 - mape: 32.8822 - val_loss: 0.2660 - val_mape: 32.5436\n",
      "Epoch 199/10000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2466 - mape: 30.1370 - val_loss: 0.2640 - val_mape: 30.9547\n",
      "Epoch 200/10000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2541 - mape: 29.7872 - val_loss: 0.2671 - val_mape: 32.6416\n",
      "Epoch 201/10000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2459 - mape: 30.0791 - val_loss: 0.2905 - val_mape: 37.5019\n",
      "Epoch 202/10000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2593 - mape: 33.4983 - val_loss: 0.2688 - val_mape: 32.9128\n",
      "Epoch 203/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2463 - mape: 30.1757 - val_loss: 0.2625 - val_mape: 30.8327\n",
      "Epoch 204/10000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2495 - mape: 29.3161 - val_loss: 0.2825 - val_mape: 35.7566\n",
      "Epoch 205/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2538 - mape: 32.1946 - val_loss: 0.2808 - val_mape: 35.4116\n",
      "Epoch 206/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2527 - mape: 31.9099 - val_loss: 0.2619 - val_mape: 30.6722\n",
      "Epoch 207/10000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2498 - mape: 29.2783 - val_loss: 0.2640 - val_mape: 32.1661\n",
      "Epoch 208/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2448 - mape: 29.8252 - val_loss: 0.2673 - val_mape: 32.9829\n",
      "Epoch 209/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2450 - mape: 30.2201 - val_loss: 0.2610 - val_mape: 30.8506\n",
      "Epoch 210/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2459 - mape: 29.0338 - val_loss: 0.2687 - val_mape: 33.0225\n",
      "Epoch 211/10000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.2452 - mape: 30.1731 - val_loss: 0.2733 - val_mape: 34.0892\n",
      "Epoch 212/10000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2473 - mape: 30.8236 - val_loss: 0.2616 - val_mape: 30.2181\n",
      "Epoch 213/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2508 - mape: 28.8840 - val_loss: 0.2608 - val_mape: 30.3249\n",
      "Epoch 214/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2469 - mape: 28.6905 - val_loss: 0.2756 - val_mape: 34.0490\n",
      "Epoch 215/10000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2493 - mape: 30.8307 - val_loss: 0.2649 - val_mape: 31.8778\n",
      "Epoch 216/10000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2429 - mape: 29.2347 - val_loss: 0.2598 - val_mape: 30.6068\n",
      "Epoch 217/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2429 - mape: 28.5801 - val_loss: 0.2776 - val_mape: 34.8184\n",
      "Epoch 218/10000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2501 - mape: 31.4063 - val_loss: 0.2648 - val_mape: 32.1229\n",
      "Epoch 219/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2425 - mape: 29.4472 - val_loss: 0.2585 - val_mape: 30.2403\n",
      "Epoch 220/10000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2432 - mape: 28.4495 - val_loss: 0.2659 - val_mape: 32.3855\n",
      "Epoch 221/10000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2428 - mape: 29.6479 - val_loss: 0.2664 - val_mape: 32.5665\n",
      "Epoch 222/10000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2428 - mape: 29.7534 - val_loss: 0.2592 - val_mape: 30.9875\n",
      "Epoch 223/10000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2407 - mape: 28.7780 - val_loss: 0.2636 - val_mape: 32.1811\n",
      "Epoch 224/10000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2412 - mape: 29.4905 - val_loss: 0.2670 - val_mape: 32.8333\n",
      "Epoch 225/10000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.2424 - mape: 29.8701 - val_loss: 0.2573 - val_mape: 30.1940\n",
      "Epoch 226/10000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.2395 - mape: 28.1086 - val_loss: 0.2577 - val_mape: 29.8478\n",
      "Epoch 227/10000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2410 - mape: 27.8944 - val_loss: 0.2694 - val_mape: 32.7409\n",
      "Epoch 228/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2445 - mape: 29.8145 - val_loss: 0.2718 - val_mape: 33.8014\n",
      "Epoch 229/10000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2453 - mape: 30.6041 - val_loss: 0.2574 - val_mape: 29.9999\n",
      "Epoch 230/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2448 - mape: 28.4456 - val_loss: 0.2568 - val_mape: 30.5549\n",
      "Epoch 231/10000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2371 - mape: 28.2248 - val_loss: 0.2666 - val_mape: 32.1287\n",
      "Epoch 232/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2426 - mape: 29.3084 - val_loss: 0.2551 - val_mape: 29.4589\n",
      "Epoch 233/10000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2397 - mape: 27.6197 - val_loss: 0.2720 - val_mape: 33.4088\n",
      "Epoch 234/10000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2459 - mape: 30.2506 - val_loss: 0.2677 - val_mape: 32.6310\n",
      "Epoch 235/10000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.2429 - mape: 29.7152 - val_loss: 0.2570 - val_mape: 29.1745\n",
      "Epoch 236/10000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.2445 - mape: 27.7304 - val_loss: 0.2545 - val_mape: 29.9035\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2360 - mape: 27.7569 - val_loss: 0.2803 - val_mape: 35.3891\n",
      "Epoch 238/10000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2529 - mape: 32.1484 - val_loss: 0.2570 - val_mape: 30.7750\n",
      "Epoch 239/10000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2362 - mape: 28.4185 - val_loss: 0.2553 - val_mape: 30.1450\n",
      "Epoch 240/10000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2359 - mape: 27.9999 - val_loss: 0.2557 - val_mape: 30.0172\n",
      "Epoch 241/10000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2364 - mape: 27.8896 - val_loss: 0.2562 - val_mape: 30.2069\n",
      "Epoch 242/10000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2364 - mape: 28.0448 - val_loss: 0.2628 - val_mape: 31.9601\n",
      "Epoch 243/10000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2394 - mape: 29.3767 - val_loss: 0.2534 - val_mape: 29.0352\n",
      "Epoch 244/10000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2408 - mape: 27.6334 - val_loss: 0.2517 - val_mape: 29.0361\n",
      "Epoch 245/10000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2371 - mape: 27.4299 - val_loss: 0.2670 - val_mape: 32.7724\n",
      "Epoch 246/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2426 - mape: 30.0469 - val_loss: 0.2533 - val_mape: 30.0931\n",
      "Epoch 247/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2341 - mape: 27.9723 - val_loss: 0.2515 - val_mape: 28.7755\n",
      "Epoch 248/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2391 - mape: 27.4020 - val_loss: 0.2503 - val_mape: 29.2453\n",
      "Epoch 249/10000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2330 - mape: 27.3415 - val_loss: 0.2561 - val_mape: 30.3520\n",
      "Epoch 250/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2351 - mape: 28.0209 - val_loss: 0.2514 - val_mape: 29.0239\n",
      "Epoch 251/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2350 - mape: 27.2168 - val_loss: 0.2715 - val_mape: 33.1294\n",
      "Epoch 252/10000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2478 - mape: 30.4907 - val_loss: 0.2715 - val_mape: 33.3378\n",
      "Epoch 253/10000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2472 - mape: 30.6166 - val_loss: 0.2678 - val_mape: 29.7071\n",
      "Epoch 254/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2608 - mape: 28.9059 - val_loss: 0.2546 - val_mape: 28.7921\n",
      "Epoch 255/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2412 - mape: 27.3928 - val_loss: 0.2785 - val_mape: 34.3103\n",
      "Epoch 256/10000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.2545 - mape: 31.6380 - val_loss: 0.2514 - val_mape: 29.4426\n",
      "Epoch 257/10000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2336 - mape: 27.5623 - val_loss: 0.2509 - val_mape: 29.0233\n",
      "Epoch 258/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2374 - mape: 27.5526 - val_loss: 0.2584 - val_mape: 31.9417\n",
      "Epoch 259/10000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2361 - mape: 29.4462 - val_loss: 0.2504 - val_mape: 29.7096\n",
      "Epoch 260/10000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2325 - mape: 27.7563 - val_loss: 0.2528 - val_mape: 28.9471\n",
      "Epoch 261/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2372 - mape: 27.2832 - val_loss: 0.2570 - val_mape: 30.3575\n",
      "Epoch 262/10000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2370 - mape: 28.1813 - val_loss: 0.2564 - val_mape: 30.9516\n",
      "Epoch 263/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2351 - mape: 28.6161 - val_loss: 0.2486 - val_mape: 29.5013\n",
      "Epoch 264/10000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2319 - mape: 27.6596 - val_loss: 0.2529 - val_mape: 30.9653\n",
      "Epoch 265/10000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2329 - mape: 28.6548 - val_loss: 0.2538 - val_mape: 31.1885\n",
      "Epoch 266/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2323 - mape: 28.7307 - val_loss: 0.2462 - val_mape: 28.6685\n",
      "Epoch 267/10000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2302 - mape: 26.9403 - val_loss: 0.2489 - val_mape: 28.6898\n",
      "Epoch 268/10000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2331 - mape: 27.0208 - val_loss: 0.2811 - val_mape: 34.5076\n",
      "Epoch 269/10000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2595 - mape: 32.1387 - val_loss: 0.2579 - val_mape: 30.6200\n",
      "Epoch 270/10000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2375 - mape: 28.4266 - val_loss: 0.2599 - val_mape: 28.9554\n",
      "Epoch 271/10000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2503 - mape: 27.9433 - val_loss: 0.2521 - val_mape: 30.7996\n",
      "Epoch 272/10000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2320 - mape: 28.6260 - val_loss: 0.3531 - val_mape: 50.9744\n",
      "Epoch 273/10000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3322 - mape: 47.8792 - val_loss: 0.2605 - val_mape: 32.0552\n",
      "Epoch 274/10000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2391 - mape: 29.6893 - val_loss: 0.2996 - val_mape: 32.9549\n",
      "Epoch 275/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2945 - mape: 32.3031 - val_loss: 0.2715 - val_mape: 30.1743\n",
      "Epoch 276/10000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2609 - mape: 28.9715 - val_loss: 0.2809 - val_mape: 35.0237\n",
      "Epoch 277/10000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2604 - mape: 32.6775 - val_loss: 0.2953 - val_mape: 38.0913\n",
      "Epoch 278/10000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2732 - mape: 35.4705 - val_loss: 0.2517 - val_mape: 28.5614\n",
      "Epoch 279/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2405 - mape: 27.3359 - val_loss: 0.2721 - val_mape: 30.1643\n",
      "Epoch 280/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2646 - mape: 29.3162 - val_loss: 0.2491 - val_mape: 30.2408\n",
      "Epoch 281/10000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2318 - mape: 28.2944 - val_loss: 0.3201 - val_mape: 44.8418\n",
      "Epoch 282/10000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2985 - mape: 41.8406 - val_loss: 0.2762 - val_mape: 35.5428\n",
      "Epoch 283/10000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2542 - mape: 32.9304 - val_loss: 0.2666 - val_mape: 29.6976\n",
      "Epoch 284/10000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2571 - mape: 28.6671 - val_loss: 0.2743 - val_mape: 30.4491\n",
      "Epoch 285/10000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.2644 - mape: 29.3310 - val_loss: 0.2533 - val_mape: 30.0813\n",
      "Epoch 286/10000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2361 - mape: 28.1707 - val_loss: 0.2799 - val_mape: 35.7993\n",
      "Epoch 287/10000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2600 - mape: 33.4823 - val_loss: 0.2607 - val_mape: 32.5513\n",
      "Epoch 288/10000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2413 - mape: 30.3750 - val_loss: 0.2456 - val_mape: 28.7421\n",
      "Epoch 289/10000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2323 - mape: 27.3083 - val_loss: 0.2522 - val_mape: 28.7460\n",
      "Epoch 290/10000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2421 - mape: 27.6518 - val_loss: 0.2449 - val_mape: 29.2346\n",
      "Epoch 291/10000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2308 - mape: 27.6918 - val_loss: 0.2557 - val_mape: 32.0961\n",
      "Epoch 292/10000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2370 - mape: 29.8682 - val_loss: 0.2488 - val_mape: 30.5418\n",
      "Epoch 293/10000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2321 - mape: 28.6791 - val_loss: 0.2432 - val_mape: 28.3644\n",
      "Epoch 294/10000\n"
     ]
    }
   ],
   "source": [
    "model = build_model ()\n",
    "history = model.fit ( x_train, y_train, epochs = 10000, batch_size = 100000 , validation_data = (x_val, y_val) )\n",
    "model.save(\"../models/classifier/{}_nodropout.h5\".format('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "accuracy = history.history['mape']\n",
    "val_accuracy = history.history['val_mape']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "l1 = ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "vl1 = ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss (mape))')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ac2= ax2.plot(epochs, accuracy, 'o', c=\"red\", label='Training acc')\n",
    "vac2= ax2.plot(epochs, val_accuracy, 'r', label='Validation acc')\n",
    "ax2.set_ylabel('mape')\n",
    "\n",
    "lns = l1 + vl1 + ac2 + vac2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=\"center right\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"acc+loss_drop.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "accuracy = history.history['mape']\n",
    "val_accuracy = history.history['val_mape']\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(prob_array, bins):\n",
    "    prob_array = np.array(prob_array)\n",
    "    plt.hist(prob_array, bins, histtype=u'step', density=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "y = np.array(y)\n",
    "bins = np.linspace(0, 0.6, 100)\n",
    "pyplot.hist(y, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "pyplot.hist(y_pred, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
